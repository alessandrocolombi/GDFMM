---
title: "Rmd_Introducing_nu"
output: pdf_document
---

# Partizione fissa

```{r 11_setup, include=FALSE, purl=FALSE}
knitr::opts_chunk$set(eval = T)
```

```{r message=FALSE, include=TRUE}
library(GDFMM)
library(ACutils)
```

Let us consider $S_{jm}\sim Gamma(\gamma_j, 1)$, $S_{jm}'\sim Gamma(\gamma_j, \nu)$. Hence, by developping some computations we have $S_{jm}' = \frac{1}{nu}S_{jm}$. Then $U$ is associated to $S$ and $U'$ to $S'$. We have that
$U' = \nu U$. Regarding the Laplace transorm, we have $\psi_{S'}(U_j') = \psi_{S}(\frac{U'_j}{\nu}) = \psi_{S}(U_j)$.

# Fixed Partition
Genero i dati per 10 gruppi. Ecco un elenco di cose che ho notato:
 : Se $\nu>1$, $U$ e $S$ esplodono, nel senso che vengono proprio infinito.
 : Inizialmente, mi sembra di capire che c'è un valore di $\nu$ da cui si vedono dei miglioramenti. Poi, ho notato che in effetti quando $\nu=1$ c'è qualcosa che non va perché mixxa solo se $\gamma_j$ sono tenuti fissi ad un valore piccolo. Ma se si mettono aleatori, non va bene. Poi c'è una zona di transizione (in questo esempio, per $\nu \approx 0.7$) in cui l'effetto dipende molto dal valore iniziale $\gamma_0$. Poi se $\nu$ diventa sufficientemente piccolo, allora si stabilizza sempre attorno allo stesso valore. 

Domanda, al momento a noi non piace il fatto che $M^*$ rimanga sempre 0 e ci piace quando invece si ottiene una certa aleatorietà. Però si attesta sempre attorno ad un valore che è circa 20. Perché? Da dove esce questo valore? Va bene?

## Genero i dati (d=10)
```{r}
d = 10               # number of groups
K = 3               # number of global clusters
mu = c(-5,0,1)   # vectors of means
sd = c(1,1,1)      # vector of sd
n_j = rep(200, d)  # set cardinality of the groups
p = matrix(0, nrow = d, ncol = K) # matrix with components weights

set.seed(124123)
Kgruppo = c()
componenti_gruppo = NULL
data = matrix(NA, nrow = d, ncol = max(n_j))     # d x max(n_j) matrix
cluster = matrix(NA, nrow = d, ncol = max(n_j))  # d x max(n_j) matrix
real_partition = c()      # real_partition is a vector of length sum(n_j), it collects all the group membership.
                          # values are collected level by level, so first all the values in level 1, the all values in level 2 and so on
                          # cluster label must always start from 0!
for(j in 1:d){
  Kgruppo[j] = sample(1:K,1) # number of clusters in each level
  componenti_gruppo[[j]] = sample(1:K,Kgruppo[j], replace = F) # choose the components
  p[j,1:Kgruppo[j]] = rep(1/Kgruppo[j], Kgruppo[j]) # set the weights all equals
  appoggio = genera_mix_gas(n = n_j[j], pro = p[j,1:Kgruppo[j]], means = mu[ componenti_gruppo[[j]] ],
                            sds = sd[ componenti_gruppo[[j]] ] )

  data[j, 1:n_j[j]] = appoggio$y
  cluster[j, 1:n_j[j]] = unlist(lapply(1:n_j[j], function(h){componenti_gruppo[[j]][appoggio$clu[h]]}))
  real_partition = c(real_partition, cluster[j, 1:n_j[j]])
}

N_m = table(real_partition)

data_level1 = data[cluster==1]
data_level2 = data[cluster==2]
data_level3 = data[cluster==3]

```

## $\nu$ = 1, $\gamma$ updated
```{r}

niter  <- 5000
burnin <- 1
thin   <- 1

option<-list("nu" = 1, "Mstar0" = 3, "Lambda0" = 3, "mu0" = 0,"sigma0"= 1, "gamma0" = 0.01,
             "Adapt_MH_hyp1"= 0.7,"Adapt_MH_hyp2"= 0.234, "Adapt_MH_power_lim"=10, "Adapt_MH_var0"=1,
             "k0"= 1/10, "nu0"=10, "alpha_gamma"=1,
             "beta_gamma"=1, "alpha_lambda"=1, "beta_lambda"=1,
             "UpdateU" = T, "UpdateM" = T, "UpdateGamma" = T, "UpdateS" = T,
             "UpdateTau" = T, "UpdateLambda" = T, "partition" = real_partition
)

GDFMM = GDFMM_sampler(data, niter, burnin, thin, seed = 123, FixPartition = T, option = option)


#Mstar
summary(GDFMM$Mstar)
plot(GDFMM$Mstar, type = 'l', main = "Mstar")


#Parametro Poisson: lambda * exp(-log_sum)
summary(GDFMM$lambda*exp(-GDFMM$log_sum))
plot(GDFMM$lambda*exp(-GDFMM$log_sum), type = 'l', main = "Poisson parameter")

#gammas
gamma = GDFMM$gamma
post_mean_gamma = rowMeans(gamma)
post_mean_gamma
matplot(x = 1:ncol(gamma), y = t(gamma), type = 'l')
# Predictive --------------------------------------------------------------

l_grid = 200
grid = seq(-25,25,length.out = l_grid)

# Predictive in all groups
Pred_all = predictive_all_groups(grid = grid, fit = GDFMM)
par(mfrow = c(1,3))
for(j in 1:3){
  hist(data[j,], freq = F, breaks = l_grid/10, col = ACutils::t_col("darkred", 70), xlim = range(grid),
             main = paste0("level = ",j))
  matplot(x = grid, y = t(Pred_all[[j]]), type = 'l', col = 'black', lty = 1, lwd = 2, add = T)
  points(x = data[j,], y = rep(0, length(data[j,])), pch = 16, col = ACutils::t_col("darkred", 10))

}
```

## $\nu$ = 1, $\gamma$ fixed and small (0.01)
```{r}

niter  <- 5000
burnin <- 1
thin   <- 1

option<-list("nu" = 1, "Mstar0" = 3, "Lambda0" = 3, "mu0" = 0,"sigma0"= 1, "gamma0" = 0.01,
             "Adapt_MH_hyp1"= 0.7,"Adapt_MH_hyp2"= 0.234, "Adapt_MH_power_lim"=10, "Adapt_MH_var0"=1,
             "k0"= 1/10, "nu0"=10, "alpha_gamma"=1,
             "beta_gamma"=1, "alpha_lambda"=1, "beta_lambda"=1,
             "UpdateU" = T, "UpdateM" = T, "UpdateGamma" = F, "UpdateS" = T,
             "UpdateTau" = T, "UpdateLambda" = T, "partition" = real_partition
)

GDFMM = GDFMM_sampler(data, niter, burnin, thin, seed = 123, FixPartition = T, option = option)


#Mstar
summary(GDFMM$Mstar)
plot(GDFMM$Mstar, type = 'l', main = "Mstar")


#Parametro Poisson: lambda * exp(-log_sum)
summary(GDFMM$lambda*exp(-GDFMM$log_sum))
plot(GDFMM$lambda*exp(-GDFMM$log_sum), type = 'l', main = "Poisson parameter")

#gammas
gamma = GDFMM$gamma
post_mean_gamma = rowMeans(gamma)
# Predictive --------------------------------------------------------------

l_grid = 200
grid = seq(-25,25,length.out = l_grid)

# Predictive in all groups
Pred_all = predictive_all_groups(grid = grid, fit = GDFMM)
par(mfrow = c(1,3))
for(j in 1:3){
  hist(data[j,], freq = F, breaks = l_grid/10, col = ACutils::t_col("darkred", 70), xlim = range(grid),
             main = paste0("level = ",j))
  matplot(x = grid, y = t(Pred_all[[j]]), type = 'l', col = 'black', lty = 1, lwd = 2, add = T)
  points(x = data[j,], y = rep(0, length(data[j,])), pch = 16, col = ACutils::t_col("darkred", 10))

}
```


## $\nu$ = 0.75, $\gamma_0=1$
Da qui in poi, fisso solo il valore iniziale e poi gamma lo lascio variare.
```{r}

niter  <- 10000
burnin <- 1
thin   <- 1

option<-list("nu" = 0.75, "Mstar0" = 3, "Lambda0" = 3, "mu0" = 0,"sigma0"= 1, "gamma0" = 1,
             "Adapt_MH_hyp1"= 0.7,"Adapt_MH_hyp2"= 0.234, "Adapt_MH_power_lim"=10, "Adapt_MH_var0"=1,
             "k0"= 1/10, "nu0"=10, "alpha_gamma"=1,
             "beta_gamma"=1, "alpha_lambda"=1, "beta_lambda"=1,
             "UpdateU" = T, "UpdateM" = T, "UpdateGamma" = T, "UpdateS" = T,
             "UpdateTau" = T, "UpdateLambda" = T, "partition" = real_partition
)

GDFMM = GDFMM_sampler(data, niter, burnin, thin, seed = 123, FixPartition = T, option = option)


#Mstar
summary(GDFMM$Mstar)
plot(GDFMM$Mstar, type = 'l', main = "Mstar")


#Parametro Poisson: lambda * exp(-log_sum)
summary(GDFMM$lambda*exp(-GDFMM$log_sum))
plot(GDFMM$lambda*exp(-GDFMM$log_sum), type = 'l', main = "Poisson parameter")

#gammas
gamma = GDFMM$gamma
post_mean_gamma = rowMeans(gamma)
post_mean_gamma
matplot(x = 1:ncol(gamma), y = t(gamma), type = 'l')
# Predictive --------------------------------------------------------------

l_grid = 200
grid = seq(-25,25,length.out = l_grid)

# Predictive in all groups
Pred_all = predictive_all_groups(grid = grid, fit = GDFMM)
par(mfrow = c(1,3))
for(j in 1:3){
  hist(data[j,], freq = F, breaks = l_grid/10, col = ACutils::t_col("darkred", 70), xlim = range(grid),
             main = paste0("level = ",j))
  matplot(x = grid, y = t(Pred_all[[j]]), type = 'l', col = 'black', lty = 1, lwd = 2, add = T)
  points(x = data[j,], y = rep(0, length(data[j,])), pch = 16, col = ACutils::t_col("darkred", 10))

}
```
Questa è stranissima. 


## $\nu$ = 0.75, $\gamma_0=0.1$
```{r}

niter  <- 10000
burnin <- 1
thin   <- 1

option<-list("nu" = 0.75, "Mstar0" = 3, "Lambda0" = 3, "mu0" = 0,"sigma0"= 1, "gamma0" = 0.1,
             "Adapt_MH_hyp1"= 0.7,"Adapt_MH_hyp2"= 0.234, "Adapt_MH_power_lim"=10, "Adapt_MH_var0"=1,
             "k0"= 1/10, "nu0"=10, "alpha_gamma"=1,
             "beta_gamma"=1, "alpha_lambda"=1, "beta_lambda"=1,
             "UpdateU" = T, "UpdateM" = T, "UpdateGamma" = T, "UpdateS" = T,
             "UpdateTau" = T, "UpdateLambda" = T, "partition" = real_partition
)

GDFMM = GDFMM_sampler(data, niter, burnin, thin, seed = 123, FixPartition = T, option = option)


#Mstar
summary(GDFMM$Mstar)
plot(GDFMM$Mstar, type = 'l', main = "Mstar")


#Parametro Poisson: lambda * exp(-log_sum)
summary(GDFMM$lambda*exp(-GDFMM$log_sum))
plot(GDFMM$lambda*exp(-GDFMM$log_sum), type = 'l', main = "Poisson parameter")

#gammas
gamma = GDFMM$gamma
post_mean_gamma = rowMeans(gamma)
post_mean_gamma
matplot(x = 1:ncol(gamma), y = t(gamma), type = 'l')
# Predictive --------------------------------------------------------------

l_grid = 200
grid = seq(-25,25,length.out = l_grid)

# Predictive in all groups
Pred_all = predictive_all_groups(grid = grid, fit = GDFMM)
par(mfrow = c(1,3))
for(j in 1:3){
  hist(data[j,], freq = F, breaks = l_grid/10, col = ACutils::t_col("darkred", 70), xlim = range(grid),
             main = paste0("level = ",j))
  matplot(x = grid, y = t(Pred_all[[j]]), type = 'l', col = 'black', lty = 1, lwd = 2, add = T)
  points(x = data[j,], y = rep(0, length(data[j,])), pch = 16, col = ACutils::t_col("darkred", 10))

}
```
Questa mixxa pochissimo 


## $\nu$ = 0.70, $\gamma_0=10$
```{r}

niter  <- 10000
burnin <- 1
thin   <- 1

option<-list("nu" = 0.7, "Mstar0" = 3, "Lambda0" = 3, "mu0" = 0,"sigma0"= 1, "gamma0" = 10,
             "Adapt_MH_hyp1"= 0.7,"Adapt_MH_hyp2"= 0.234, "Adapt_MH_power_lim"=10, "Adapt_MH_var0"=1,
             "k0"= 1/10, "nu0"=10, "alpha_gamma"=1,
             "beta_gamma"=1, "alpha_lambda"=1, "beta_lambda"=1,
             "UpdateU" = T, "UpdateM" = T, "UpdateGamma" = T, "UpdateS" = T,
             "UpdateTau" = T, "UpdateLambda" = T, "partition" = real_partition
)

GDFMM = GDFMM_sampler(data, niter, burnin, thin, seed = 123, FixPartition = T, option = option)


#Mstar
summary(GDFMM$Mstar)
plot(GDFMM$Mstar, type = 'l', main = "Mstar")


#Parametro Poisson: lambda * exp(-log_sum)
summary(GDFMM$lambda*exp(-GDFMM$log_sum))
plot(GDFMM$lambda*exp(-GDFMM$log_sum), type = 'l', main = "Poisson parameter")

#gammas
gamma = GDFMM$gamma
post_mean_gamma = rowMeans(gamma)
post_mean_gamma
matplot(x = 1:ncol(gamma), y = t(gamma), type = 'l')
# Predictive --------------------------------------------------------------

l_grid = 200
grid = seq(-25,25,length.out = l_grid)

# Predictive in all groups
Pred_all = predictive_all_groups(grid = grid, fit = GDFMM)
par(mfrow = c(1,3))
for(j in 1:3){
  hist(data[j,], freq = F, breaks = l_grid/10, col = ACutils::t_col("darkred", 70), xlim = range(grid),
             main = paste0("level = ",j))
  matplot(x = grid, y = t(Pred_all[[j]]), type = 'l', col = 'black', lty = 1, lwd = 2, add = T)
  points(x = data[j,], y = rep(0, length(data[j,])), pch = 16, col = ACutils::t_col("darkred", 10))

}
```
Dopo poche iterzioni, si assesta attorno a 15 o 20.

## $\nu$ = 0.70, $\gamma_0=1$
```{r}

niter  <- 10000
burnin <- 1
thin   <- 1

option<-list("nu" = 0.7, "Mstar0" = 3, "Lambda0" = 3, "mu0" = 0,"sigma0"= 1, "gamma0" = 1,
             "Adapt_MH_hyp1"= 0.7,"Adapt_MH_hyp2"= 0.234, "Adapt_MH_power_lim"=10, "Adapt_MH_var0"=1,
             "k0"= 1/10, "nu0"=10, "alpha_gamma"=1,
             "beta_gamma"=1, "alpha_lambda"=1, "beta_lambda"=1,
             "UpdateU" = T, "UpdateM" = T, "UpdateGamma" = T, "UpdateS" = T,
             "UpdateTau" = T, "UpdateLambda" = T, "partition" = real_partition
)

GDFMM = GDFMM_sampler(data, niter, burnin, thin, seed = 123, FixPartition = T, option = option)


#Mstar
summary(GDFMM$Mstar)
plot(GDFMM$Mstar, type = 'l', main = "Mstar")


#Parametro Poisson: lambda * exp(-log_sum)
summary(GDFMM$lambda*exp(-GDFMM$log_sum))
plot(GDFMM$lambda*exp(-GDFMM$log_sum), type = 'l', main = "Poisson parameter")

#gammas
gamma = GDFMM$gamma
post_mean_gamma = rowMeans(gamma)
post_mean_gamma
matplot(x = 1:ncol(gamma), y = t(gamma), type = 'l')
# Predictive --------------------------------------------------------------

l_grid = 200
grid = seq(-25,25,length.out = l_grid)

# Predictive in all groups
Pred_all = predictive_all_groups(grid = grid, fit = GDFMM)
par(mfrow = c(1,3))
for(j in 1:3){
  hist(data[j,], freq = F, breaks = l_grid/10, col = ACutils::t_col("darkred", 70), xlim = range(grid),
             main = paste0("level = ",j))
  matplot(x = grid, y = t(Pred_all[[j]]), type = 'l', col = 'black', lty = 1, lwd = 2, add = T)
  points(x = data[j,], y = rep(0, length(data[j,])), pch = 16, col = ACutils::t_col("darkred", 10))

}
```
Simile a prima ma con un burnin molto più lungo.

## $\nu$ = 1/10
```{r}

niter  <- 10000
burnin <- 1
thin   <- 1

option<-list("nu" = 1/10, "Mstar0" = 3, "Lambda0" = 3, "mu0" = 0,"sigma0"= 1, "gamma0" = 0.01,
             "Adapt_MH_hyp1"= 0.7,"Adapt_MH_hyp2"= 0.234, "Adapt_MH_power_lim"=10, "Adapt_MH_var0"=1,
             "k0"= 1/10, "nu0"=10, "alpha_gamma"=1,
             "beta_gamma"=1, "alpha_lambda"=1, "beta_lambda"=1,
             "UpdateU" = T, "UpdateM" = T, "UpdateGamma" = T, "UpdateS" = T,
             "UpdateTau" = T, "UpdateLambda" = T, "partition" = real_partition
)

GDFMM = GDFMM_sampler(data, niter, burnin, thin, seed = 123, FixPartition = T, option = option)


#Mstar
summary(GDFMM$Mstar)
plot(GDFMM$Mstar, type = 'l', main = "Mstar")


#Parametro Poisson: lambda * exp(-log_sum)
summary(GDFMM$lambda*exp(-GDFMM$log_sum))
plot(GDFMM$lambda*exp(-GDFMM$log_sum), type = 'l', main = "Poisson parameter")

#gammas
gamma = GDFMM$gamma
post_mean_gamma = rowMeans(gamma)
post_mean_gamma
matplot(x = 1:ncol(gamma), y = t(gamma), type = 'l')
# Predictive --------------------------------------------------------------

l_grid = 200
grid = seq(-25,25,length.out = l_grid)

# Predictive in all groups
Pred_all = predictive_all_groups(grid = grid, fit = GDFMM)
par(mfrow = c(1,3))
for(j in 1:3){
  hist(data[j,], freq = F, breaks = l_grid/10, col = ACutils::t_col("darkred", 70), xlim = range(grid),
             main = paste0("level = ",j))
  matplot(x = grid, y = t(Pred_all[[j]]), type = 'l', col = 'black', lty = 1, lwd = 2, add = T)
  points(x = data[j,], y = rep(0, length(data[j,])), pch = 16, col = ACutils::t_col("darkred", 10))

}
```
Così è molto più stabile, non dipende più dal valore di $\gamma_0$ (a meno che non si mette il valore iniziale molto grande, tipo 1000).

## $\nu$ = 1/100
```{r}

niter  <- 5000
burnin <- 5000
thin   <- 1

option<-list("nu" = 1/100, "Mstar0" = 3, "Lambda0" = 3, "mu0" = 0,"sigma0"= 1, "gamma0" = 100,
             "Adapt_MH_hyp1"= 0.7,"Adapt_MH_hyp2"= 0.234, "Adapt_MH_power_lim"=10, "Adapt_MH_var0"=1,
             "k0"= 1/10, "nu0"=10, "alpha_gamma"=1,
             "beta_gamma"=1, "alpha_lambda"=1, "beta_lambda"=1,
             "UpdateU" = T, "UpdateM" = T, "UpdateGamma" = T, "UpdateS" = T,
             "UpdateTau" = T, "UpdateLambda" = T, "partition" = real_partition
)

GDFMM = GDFMM_sampler(data, niter, burnin, thin, seed = 123, FixPartition = T, option = option)


#Mstar
summary(GDFMM$Mstar)
plot(GDFMM$Mstar, type = 'l', main = "Mstar")


#Parametro Poisson: lambda * exp(-log_sum)
summary(GDFMM$lambda*exp(-GDFMM$log_sum))
plot(GDFMM$lambda*exp(-GDFMM$log_sum), type = 'l', main = "Poisson parameter")

#gammas
gamma = GDFMM$gamma
post_mean_gamma = rowMeans(gamma)
post_mean_gamma
matplot(x = 1:ncol(gamma), y = t(gamma), type = 'l')
# Predictive --------------------------------------------------------------

l_grid = 200
grid = seq(-25,25,length.out = l_grid)

# Predictive in all groups
Pred_all = predictive_all_groups(grid = grid, fit = GDFMM)
par(mfrow = c(1,3))
for(j in 1:3){
  hist(data[j,], freq = F, breaks = l_grid/10, col = ACutils::t_col("darkred", 70), xlim = range(grid),
             main = paste0("level = ",j))
  matplot(x = grid, y = t(Pred_all[[j]]), type = 'l', col = 'black', lty = 1, lwd = 2, add = T)
  points(x = data[j,], y = rep(0, length(data[j,])), pch = 16, col = ACutils::t_col("darkred", 10))

}
```
Qua l'effetto del valore iniziale è decisamente mitigato, inoltre la fase per arrivare alla convergenza della catenza è un po' più smooth, non è più a scalino.


# Plot funzione
Voglio capire come sono fatte le funzioni $f(u,\gamma) = \frac{1}{(u+1)^\gamma}$.
Inizio con un plot delle linee di livello. Si vede che se la U è maggiore di 1, allora la gamma deve essere davvero piccolissima per avere dei valori vicini ad 1 (NB, ricordarsi che questo è solo uno dei d termini che sono coinvolti, il coefficiente che vediamo noi è il prodotto di d termini fatti così). Stessa cosa per quando $\gamma>1$. Diciamo che ci si aspetta che entrambi i valori siano minori di 1.

```{r}
f = function(l){
  u = l[[1]]
  gamma = l[[2]]
  return( 1/(1+u)^gamma )
}

Umin = 0
Umax = 4
gamma_min = 0.001
gamma_max = 4


U <- seq(Umin,Umax,length=100)
gamma <- seq(gamma_min,gamma_max,length=100)

grid <- expand.grid(U, gamma)
f_values <- apply(grid, 1, f)
f_values <- matrix(f_values, nrow = length(U),
                     ncol = length(gamma), byrow=F)

# plot with confindence levels
#levels <- seq(0,1,length.out = 15)
levels <- c(1,0.95,0.9,0.8,0.7,0.6,0.5,0.25,0.1,0.05)
my_col = hcl.colors (n= length( levels ), palette = " Zissou1 ")
contour(U, gamma, f_values, col = my_col,
        levels = levels, labels = stringr::str_trunc(as.character(levels), width = 4, ellipsis = ""),
        xlab="U", ylab=expression(gamma), 
        xlim = c(Umin-0.05,Umax+0.05), ylim = c(gamma_min-0.05,gamma_max+0.05)
        )


```
Provo ad indagare valori più vicini a zero. Qui è per $U\in(0,0.5)$.
```{r}
Umin = 0
Umax = 0.5
gamma_min = 0.001
gamma_max = 4


U <- seq(Umin,Umax,length=100)
gamma <- seq(gamma_min,gamma_max,length=100)

grid <- expand.grid(U, gamma)
f_values <- apply(grid, 1, f)
f_values <- matrix(f_values, nrow = length(U),
                     ncol = length(gamma), byrow=F)

# plot with confindence levels
#levels <- seq(0,1,length.out = 15)
levels <- c(1,0.95,0.9,0.8,0.7,0.6,0.5,0.25,0.1,0.05)
my_col = hcl.colors (n= length( levels ), palette = " Zissou1 ")
contour(U, gamma, f_values, col = my_col,
        levels = levels, labels = stringr::str_trunc(as.character(levels), width = 4, ellipsis = ""),
        xlab="U", ylab=expression(gamma), 
        xlim = c(Umin-0.05,Umax+0.05), ylim = c(gamma_min-0.05,gamma_max+0.05)
        )
```
Provo ad indagare valori più vicini a zero. Qui è per $\gamma\in(0.001,0.5)$.
```{r}
Umin = 0
Umax = 4
gamma_min = 0.001
gamma_max = 0.5


U <- seq(Umin,Umax,length=100)
gamma <- seq(gamma_min,gamma_max,length=100)

grid <- expand.grid(U, gamma)
f_values <- apply(grid, 1, f)
f_values <- matrix(f_values, nrow = length(U),
                     ncol = length(gamma), byrow=F)

# plot with confindence levels
#levels <- seq(0,1,length.out = 15)
levels <- c(1,0.95,0.9,0.8,0.7,0.6,0.5,0.25,0.1,0.05)
my_col = hcl.colors (n= length( levels ), palette = " Zissou1 ")
contour(U, gamma, f_values, col = my_col,
        levels = levels, labels = stringr::str_trunc(as.character(levels), width = 4, ellipsis = ""),
        xlab="U", ylab=expression(gamma), 
        xlim = c(Umin-0.05,Umax+0.05), ylim = c(gamma_min-0.05,gamma_max+0.05)
        )
```
Faccio i plot uni-dimensionali - gamma
```{r}
f_gamma = function(x, u){
  return( 1/(1+u)^x )
}

U = c(0.1,0.25,0.5,1,2,4)
gamma_min = 0.001
gamma_max = 4

par(mfrow = c(2,3))
for(i in 1:length(U)){
  curve(expr = f_gamma(x = x, u = U[i]), from = gamma_min, to = gamma_max,
        ylab = "f(gamma, U)", xlab = expression(gamma), 
        main = paste0("U = ", U[i]), ylim = c(0,1))  
}

```
Faccio i plot uni-dimensionali - U
```{r}
f_u = function(x, gamma){
  return( 1/(1+x)^gamma )
}

gamma = c(0.01,0.25,0.5,1,2,4)
Umin = 0
Umax = 4

par(mfrow = c(2,3))
for(i in 1:length(U)){
  curve(expr = f_u(x = x, gamma = gamma[i]), from = Umin, to = Umax,
        ylab = "f(gamma, U)", xlab = expression(U), 
        main = paste(expression(gamma)," = ",gamma[i]), ylim = c(0,1))  
}

```













