---
title: "Bebuggin Neal 3"
author: "Alessandro Colombi"
date: "9/2/2023"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Librerie
```{r}
suppressWarnings(suppressPackageStartupMessages(library(GDFMM)))
suppressWarnings(suppressPackageStartupMessages(library(ACutils)))
suppressWarnings(suppressPackageStartupMessages(library(tidyverse)))
suppressWarnings(suppressPackageStartupMessages(library(RColorBrewer)))
suppressWarnings(suppressPackageStartupMessages(library(salso)))
suppressWarnings(suppressPackageStartupMessages(library(wesanderson)))
suppressWarnings(suppressPackageStartupMessages(library(mcclust.ext)))
suppressWarnings(suppressPackageStartupMessages(library(abind)))
```

# Custom functions

```{r}
my_invgamma = function(x, nu0, sigma0){
  a = nu0/2
  b = a*sigma0
  b^a/gamma(a) * (1/x)^(a+1) * exp(-b/x)
}

```




# Simulate data

Differenza con Modotti: per semplicità inizio assicurandomi che tutti i 100 giocatori abbiano almeno un lancio per ogni stagione. Questo perché simulare i dati altrimenti diventa piu difficile. In pratica, non cambia niente tanto
```{r}

#1) Per prima cosa, estraggo un singolo valore per ogni giocatore in ogni stagione. Lo faccio estraendo da una mistura
n = 100
d = 5                         # number of seasons
K = 7                         # number of global clusters
mu = c(-4,-2 ,-2,0  ,2  ,2,4)      # vectors of means
sd = sqrt(c(1 ,0.5, 1,0.5,0.5,1,1))   # vector of sd
mix_probs = matrix(c(0.2,0.2,0,0.2,0.2,0,0.2,
                     0.25,0,0.25,0,0,0.25,0.25,
                     0.2,0.2,0,0.2,0.2,0,0.2,
                     0.2,0,0,0.6,0,0,0.2,
                     0,0,0,0.75,0,0.25,0),
                   nrow = d, ncol = K, byrow = T)

seed = 1234
set.seed(seed)
lambda_s = c(4,4,2.5,1.5,1.5)
N_ji = unlist(lapply( as.list(lambda_s), FUN = function(x){rpois(n = n, lambda = x)} ))
N_ji = matrix(N_ji,nrow = d, ncol = n, byrow = T )
N_ji = N_ji + 1
zeros = apply(N_ji, 1, function(N_j){sum(N_j == 0)})
n_j = rep(n,d) - zeros

genD = simulate_data(d = d, K = K, p = mix_probs, mu = mu, sd = sd, n_j = n_j, seed = seed)
real_partition = genD$real_partition

# creo un piccolo tibble che mi definisce nomi, stagioni e cluster vero
names = c()
SeasonNumber = c()
for(j in 1:d){
  names = c(names, seq(1,n_j[j]))
  SeasonNumber = c(SeasonNumber, rep(j,n_j[j]))
}

data_small = tibble( ID = names,
                     SeasonNumber = SeasonNumber,
                     TrueClustering = real_partition )

# ora riempio la struttura di dati vera e propria
data = tibble( "ID" = factor(), 
               "SeasonNumber" = factor(), 
               "Result" = numeric(),
               "t_ji" = numeric(),
               "TrueClustering" = factor() ) 

set.seed(seed)
for(h in 1:nrow(data_small)){
  j = data_small$SeasonNumber[h]
  i = data_small$ID[h]
  m = data_small$TrueClustering[h]
  Result = rnorm(n = N_ji[j,i], mean = mu[m], sd = sd[m])
  t_ji   = j - 0.5 + rnorm(n = N_ji[j,i], mean = 0, sd = 1/5)

  temp = tibble( "ID" = as.factor( rep(i,N_ji[j,i]) ), 
                 "SeasonNumber" = as.factor( rep(j,N_ji[j,i]) ), 
                 "Result" = Result,
                 "t_ji" = t_ji,
                 "TrueClustering" = as.factor( rep(m,N_ji[j,i]) ) ) 
  data = data %>% rbind(temp)
}

```

```{r}
mycol_trueclust = hcl.colors(n=K,palette = "Zissou1")
cols = data$TrueClustering
levels(cols) = mycol_trueclust
cols = as.character(cols)


seasons = 1:d

par(mar = c(4,4,2,1))
plot( x = data$t_ji, 
      y = data$Result,
      ylab = "Result", xlab = "Season",
      pch = 16, cex = 0.5, col = cols)
abline(v = seasons, lty = 2, col = "grey45", lwd = 1)
```

### Plot istogrammi (no covariate)
```{r}
mycol_trueclust = hcl.colors(n=K,palette = "Zissou1")
for(j in 1:d){
  plot(0,0,main = paste0("Season ",j),xlab = "Result", type = "n", xlim = range(data$Result), ylim = c(0,1))
  for(k in 1:K){
      res = data %>% filter(SeasonNumber == j) %>% filter(TrueClustering == k) %>% pull(Result)
      if(length(res)>0)
        hist(res, freq = FALSE, nclass = "fd", col=mycol_trueclust[k], add = T)
  }

}

```


## Hyperparameters 

$P_0$
```{r}
Res_range = range( data$Result )
R = Res_range[2] - Res_range[1]
mu0 = mean(data$Result) # should be 0
k0  = 1/R^2
nu0 = 10
sigma0 = 10#*(100*R/1)
c("mu0"=mu0,"k0"=k0,"nu0"=nu0,"sigma0"=sigma0)

scale = sqrt( (k0 + 1)/(k0) * sigma0 )
mean_marginal = mu0
var_marginal  = nu0/(nu0-2) * scale^2

mean_marginal
var_marginal
```
Plot di $P_0$
```{r}
xrange = c(-50,50)
l_grid = 1000
grid = seq(xrange[1],xrange[2],length.out = l_grid)
   
#par(mfrow = c(1,3), mar = c(2,2,2,1), bty = "l")
# Qua plotto la marginale
Prior_grid = GDFMM:::dnct(x = grid, n0 = nu0, mu0 = mu0, gamma0 = scale)
par(mar = c(2,2,2,1), bty = "l")
plot(1,1, xlim = xrange, ylim = c(0,max(Prior_grid)),
     type = "n",
     main = "Marginal data Density")
grid(lty = 1,lwd = 2,col = "gray90" )
points(x = na.omit(as.numeric(data$Result)), 
       y = rep(0, length(na.omit(as.numeric(data$Result)))), 
       ylim = c(0,0.1),
       pch = 16)
points(grid, Prior_grid, col = "black", lwd = 2, type = "l")
  
# Qua plotto la inverse-gamma
sigma_grid = seq(1e-5, 100, length.out = 1000)
par(mar = c(2,2,2,1), bty = "l")
plot(x = sigma_grid, y = my_invgamma(sigma_grid, nu0 = nu0, sigma0 = sigma0), 
     main = "Inverse-gamma prior Density", type = "l", lwd = 2, lty = 1)
grid(lty = 1,lwd = 2,col = "gray90" )
legend("topright", legend = c( "empricial var", 
                               paste0("InvGamma(",nu0/2,", ",round(sigma0*nu0/2, digits = 3),")")  ),
       lwd = 2, lty = c(2,1), col = c("grey45","black"))
 
# Qua invece plotto la marginale di mu
scale_mu = sqrt( sigma0/k0 )
Mar_mu_grid = GDFMM:::dnct(x = grid, n0 = nu0, mu0 = mu0, gamma0 = scale_mu)
par(mar = c(2,2,2,1), bty = "l")
plot(1,1, xlim = xrange, ylim = c(0,max(Mar_mu_grid)),
     type = "n",
     main = "Marginal mu Density")
grid(lty = 1,lwd = 2,col = "gray90" )
points(grid, Mar_mu_grid, col = "black", lwd = 2, type = "l")
points(x = na.omit(as.numeric(data$Result)), 
       y = rep(0, length(na.omit(as.numeric(data$Result)))), 
       ylim = c(0,0.1),
       pch = 16)

```

$(\Lambda,\gamma_1,\dots,\gamma_d)$ prior elicitation
```{r}
Exp_Lambda   =  50
Var_Lambda   =   5
gamma_guess  =  0.01
Lambda_guess = Exp_Lambda

b_lambda = Exp_Lambda/Var_Lambda
a_lambda = Exp_Lambda * b_lambda

a_gamma = a_lambda/d
b_gamma = a_gamma / (gamma_guess * Lambda_guess) 

# plot
lambda_prior = rgamma(n=10000, shape = a_lambda, rate = b_lambda)
gamma_mar_prior = rgamma(n=10000, shape = a_gamma, rate = lambda_prior*b_gamma)
par(mar = c(2,2,2,1), bty = "l")
plot(density(gamma_mar_prior), lwd = 2, main = "Marginal for gamma", ylab = " ")

# cat("\n quantile for L(gamma) (MC estimate) \n")
# quantile(gamma_mar_prior, probs = c(0.5, 0.95, 0.99))

grid_lambda = seq(1e-8,100,length.out = 10000)
par(mar = c(2,2,2,1), bty = "l")
plot(grid_lambda, dgamma(grid_lambda, shape = a_lambda, rate = b_lambda), 
     lwd = 2, lty = 1, type = "l", main = "prior for lambda", ylab = " ")

```


## Run 


### Initial values

Qui invece che prendere tutte le osservazioni prendo solo quella media
```{r}
data_med4season = data %>% group_by(ID,SeasonNumber) %>% 
                                    mutate(MedResult = mean(Result)) %>%
                                    select(ID,SeasonNumber,Result, MedResult,t_ji) %>%
                                    distinct(ID,SeasonNumber, .keep_all = TRUE) %>% 
                                    ungroup() %>% arrange(SeasonNumber)

data_med4season
```

```{r}
Ncenters = 5
ymedian = data_med4season %>% pull(MedResult)
Kmeans0 = kmeans(x = ymedian, centers = Ncenters, iter.max = 50, nstart = 10 )
KmeansCl = Kmeans0$cluster
centers = Kmeans0$centers
data_med4season = data_med4season %>% cbind("Kmeans" = KmeansCl)
```

Plot solo dei valori medi
```{r}

mycol_clus = hcl.colors(n = length(table(KmeansCl)), palette = "Temps")
cols = as.factor(data_med4season$Kmeans)
levels(cols) = mycol_clus
cols = as.character(cols)

seasons = 1:d
par(mar = c(4,4,2,1))
plot( x = data_med4season$t_ji, 
      y = data_med4season$MedResult,
      ylab = "Result", xlab = "Season",
      pch = 16, cex = 0.5, col = cols)
abline(v = seasons, lty = 2, col = "grey45", lwd = 1)
#abline(h = centers, lty = 2, col = "black", lwd = 0.1)
```
Plot di tutti i valori
```{r}
data_with_init = data %>% left_join(data_med4season %>% 
                                     select("ID","SeasonNumber","MedResult","Kmeans"), 
                                     by = c("ID","SeasonNumber"))

mycol_clus = hcl.colors(n = length(table(KmeansCl)), palette = "Temps")
cols = as.factor(data_with_init$Kmeans)
levels(cols) = mycol_clus
cols = as.character(cols)

seasons = 1:d
par(mar = c(4,4,2,1))
plot( x = data_with_init$t_ji, 
      y = data_with_init$Result,
      ylab = "Result", xlab = "Season",
      pch = 16, cex = 0.5, col = cols)
abline(v = seasons, lty = 2, col = "grey45", lwd = 1)

```



### Setup
Leggo i dati nel modo in cui poi devono essere inseriti

```{r}

dt = input_handle(data_with_init[,c(1:3,7)], intercept = FALSE)

#load("dt_d19_data51415.Rdat")
#load("dt_d19_data51415_age.Rdat")
n = dt$n
d = dt$d
r = dt$r
n_j = dt$n_j

#save(dt, file = "dt_d19_data51415_age.Rdat")
#save(dt, file = "dt_d19_data51415.Rdat")
#View(dt)
n;d;r;sum(n_j);sum(dt$N_ji)

```


```{r}
niter  <-  500#0
burnin <-  1
thin   <-    1


# initial values
beta0 = rep(-2,dt$r)
Sigma0 = diag(dt$r)

Lambda0 = Exp_Lambda
gamma0 = rep(0.25,d)#rep(0.025,d)#1/n_j # per ora il valore magico è 0.025
Mstar0 = 3

cluster_mean = data_med4season %>% group_by(Kmeans) %>% 
                summarise(ClusterMean = mean(Result)) %>% ungroup() %>% pull(ClusterMean)
cluster_var  = data_med4season %>% group_by(Kmeans) %>% 
                summarise(ClusterVar = var(Result)) %>% ungroup() %>% pull(ClusterVar)
initial_partition = unlist(unlist(dt$initialPartition))


option = set_options( "mu0" = mu0,"sigma0"= sigma0, "k0"= k0, "nu0"=nu0, 
                      "Adapt_MH_hyp2" = 0.234, "Adapt_MH_var0"=0.1,
                      "proposal_Mstar" = 1,
                      "Lambda0" = Lambda0, "gamma0" = gamma0, "Mstar0" = Mstar0,
                      "beta0" = beta0, "Sigma0" = Sigma0,
                      "alpha_gamma" = a_gamma, "beta_gamma" = b_gamma, 
                      "alpha_lambda" = a_lambda, "beta_lambda" = b_lambda,
                      "init_mean_cluster" = c(centers, rep(0,Mstar0)), 
                      "init_var_cluster" = c(cluster_var, rep(1,Mstar0)), 
                      "partition" = initial_partition,
                      "IncludeCovariates" = FALSE,
                      "UpdateU" = T, "UpdateM" = T, "UpdateGamma" = T, 
                      "UpdateS" = T, "UpdateTau" = T, "UpdateLambda" = T,
                      "UpdateBeta" = F )

prior = "Normal-InvGamma"


```


```{r}
GDFMM = ConditionalSampler(dt[1:11], niter, burnin, thin, seed = 123, option = option, FixPartition = F,
                           P0.prior = prior, algorithm = "Neal2")
```


### Chains
```{r, echo = F}
if(option$UpdateLambda){
  #Lambda
  plot(GDFMM$lambda, type = 'l', main = expression(Lambda))
  hist(GDFMM$lambda, main = expression(Lambda))
}


if(option$UpdateM){
  # Mstar
  par(bty = "l")
  plot(GDFMM$Mstar, type = 'l', main = "Mstar")
  #acf(GDFMM$Mstar)
}


if(option$UpdateGamma){
  # gamma
  #par(mfrow = c(4,5))
  for(j in 1:d){
    plot(GDFMM$gamma[j,], type = 'l', main = paste0(expression(gamma), "_",j))
  }
  
  # 
  # par(mfrow = c(1,d), mar = c(2,2,1,1))
  # for(j in 1:d){
  #   acf(GDFMM$gamma[j,], main = paste0("ACF - ",expression(gamma), "_",j))
  # }
}



# U
# par(mfrow = c(1,d))
for(j in 1:d){
  plot(GDFMM$U[j,], type = 'l', main = paste0("U_",j))
}

# K
par(mfrow = c(1,1), bty = "l")
plot(GDFMM$K, type = 'l', main = "K")

par(mfrow = c(1,1), bty = "l")
barplot(table(GDFMM$K), main = "Hist - K")

# sigma (solo per il caso con prior Normal)
if(prior == "Normal"){
  sigma = unlist(lapply(GDFMM$sigma, FUN = function(sigma_it){sigma_it[1]}))
  par(mfrow = c(1,2), bty = "l")
  plot(sigma, type = 'l', main = "sigma^2 (variance) - traceplot")
  plot(density(sigma), main = "sigma^2 (variance) - density")  
}


```


### Clustering
```{r}

# Get labels for each iterations for each data point
part_matrix <- GDFMM$Partition[25000:50000,] #GDFMM$Partition is a (n_iter x n_data) matrix

# Compute similarity matrix
sim_matrix <- psm(part_matrix)


heatmap(sim_matrix)


#binder_sara = minbinder(sim_matrix)
VI_sara = minVI(sim_matrix)

#table(binder_sara$cl)
table(VI_sara$cl)
table(real_partition)


# inganno
#VI_sara = list("cl" = c(part_matrix)+1)
```

```{r}
dt$finalPartition = vector("list", length = d)
dt$finalPartition = lapply(1:d, FUN = function(s){dt$finalPartition[[s]] = vector("list", length = n) })
dt$Clustering = vector("list", length = d)
dt$Clustering = lapply(1:d, FUN = function(s){dt$finalPartition[[s]] = vector("list", length = n) })

counter_obs = 1
for(j in 1:d){
  for(i in 1:n){
    if(dt$N_ji[j,i] > 0){
      dt$Clustering[[j]][[i]] = GDFMM$Partition[,counter_obs]+1 # parte da 0 quella salvata
      dt$finalPartition[[j]][[i]] = VI_sara$cl[counter_obs]
      counter_obs = counter_obs + 1
    }
  }
}

```


Se invece ho fissato il clustering e voglio quello 
```{r}
#dt$finalPartition = dt$initialPartition


```

### Level dependent clustering
```{r}
Local_Clustering = list("list", length = d)
idx_start = c(1,cumsum(n_j)[1:(d-1)]+1)
idx_end = cumsum(n_j)
Kj = matrix(0,nrow = niter, ncol = d)
for(j in 1:d){
  Local_Clustering[[j]] = GDFMM$Partition[ , idx_start[j]:idx_end[j] ]
  Kj[,j] = apply(Local_Clustering[[j]], 1, FUN = function(Part_it){length(table(Part_it))})
  par(mfrow = c(1,2), bty = "l")
  plot(Kj[,j], type = 'l', main = paste0("Local K in Season ",j))
  barplot(table(Kj[,j]), main = paste0("Local K in Season ",j))

}
```


## Interpretation & Visualization

Questo va bene solo con il clustering finale (o con quello fisso)
```{r}
# data_med4season = data_med4season %>% cbind("Clustering" = VI_sara$cl)
# data_med4season

data_med4season$Clustering = rep(0,nrow(data_med4season))
for(idx in 1:nrow(data_med4season)){
  id = data_med4season$ID[idx]
  season_num = data_med4season$SeasonNumber[idx]
  nobs = which(dt$ID_i == id)
  data_med4season$Clustering[idx] = dt$finalPartition[[season_num]][[nobs]]
}
```

### Plot final clustering

Plot di tutti i valori, colorati in base al loro cluster di appartenenza
```{r}
# plot del vero clustering
seasons = 1:d
mycol_trueclust = hcl.colors(n=K,palette = "Zissou1")
cols = data$TrueClustering
levels(cols) = mycol_trueclust
cols = as.character(cols)

par(mar = c(4,4,2,1))
plot( x = data$t_ji, 
      y = data$Result,
      ylab = "Result", xlab = "Season", main = "True clustering",
      pch = 16, cex = 0.5, col = cols)
abline(v = seasons, lty = 2, col = "grey45", lwd = 1)

# plot clustering stimato
data_with_clustering = data %>% 
                        left_join(data_med4season %>% 
                                   select("ID","SeasonNumber","MedResult","Clustering"), 
                                   by = c("ID","SeasonNumber"))

mycol_clus = hcl.colors(n = length(table(data_med4season$Clustering)), palette = "Temps")
cols = as.factor(data_with_clustering$Clustering)
levels(cols) = mycol_clus
cols = as.character(cols)



par(mar = c(4,4,2,1))
plot( x = data_with_clustering$t_ji, 
      y = data_with_clustering$Result,
      ylab = "Result", xlab = "Season", main = "Final clustering",
      pch = 16, cex = 0.5, col = cols)
abline(v = seasons, lty = 2, col = "grey45", lwd = 1)
```




### Plot clusters

Plotto solo i dati che appartengono allo stesso cluster, in più, li coloro in base al sesso
```{r}
Nclus = length(table(data_with_clustering$Clustering))
mycol_clus = hcl.colors(n = Nclus, palette = "Temps")
mycol_gender = c("deepskyblue3", "palevioletred1")

seasons = 1:d


for( cl in 1:Nclus ){
  temp = data_with_clustering %>% filter(Clustering == cl)

  par(mar = c(4,4,2,1))
  plot( x = temp$t_ji, 
        y = temp$Result,
        ylab = "Result", xlab = "Season",
        main = paste0("Data in cluster ",cl),
        xlim = range(data$t_ji),
        ylim = range(data$Result),
        pch = 16, cex = 0.5, col = mycol_clus[cl])
  abline(v = seasons, lty = 2, col = "grey45", lwd = 1)

}


```



## Density estimation


```{r}
xrange = c(-10,10)
l_grid = 200
grid = seq(xrange[1],xrange[2],length.out = l_grid)
# Predictive in all groups
Pred_all = predictive_all_groups(grid = grid, fit = GDFMM, burnin = 10000)

```



```{r}

idx_start = c(1,cumsum(n_j)[1:(d-1)]+1)
idx_end = cumsum(n_j)
mycol = hcl.colors(n=3,palette = "Zissou1")

Nclus = length(table(data_with_clustering$Clustering))
mycol_cluster = hcl.colors(n=Nclus, palette = "Berlin")


for(j in 1:d){
  par(mfrow = c(1,1), mar = c(2,2,1,1))
  plot(0,0,main = paste0("Season ",j),xlab = "Result", type = "n", xlim = range(data$Result), ylim = c(0,1))
  for(k in 1:Nclus){
      res = data_with_clustering %>% filter(SeasonNumber == j) %>% filter(Clustering == k) %>% pull(Result)
      if(length(res)>0)
        hist(res, freq = FALSE, nclass = "fd", col=mycol_cluster[k], add = T)
  }
  polygon( c(grid, rev(grid)),
           c(Pred_all[[j]][1,], rev(Pred_all[[j]][3,])),
           col = ACutils::t_col(mycol[1], percent = 45),
           border = NA  )
  lines(x = grid, y = Pred_all[[j]][2,], col = mycol[1], lwd = 3) #0.5

  points(grid, GDFMM::dmix(x = grid, w_j = mix_probs[j,], mu_vec = mu, sigma_vec = sd),
         col = "red", lwd = 2, type = "l")
  legend("topright", col = c(mycol[1],"red"), legend =c("Stimata","Vera"),lwd = 2)
}

```



# fine































