---
title: "Prior Number of Clusters"
author: "Alessandro Colombi"
date: "9/2/2023"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Librerie
```{r}
suppressWarnings(suppressPackageStartupMessages(library(GDFMM)))
suppressWarnings(suppressPackageStartupMessages(library(ACutils)))
suppressWarnings(suppressPackageStartupMessages(library(tidyverse)))
suppressWarnings(suppressPackageStartupMessages(library(RColorBrewer)))
suppressWarnings(suppressPackageStartupMessages(library(salso)))
suppressWarnings(suppressPackageStartupMessages(library(wesanderson)))
suppressWarnings(suppressPackageStartupMessages(library(mcclust.ext)))
suppressWarnings(suppressPackageStartupMessages(library(abind)))
```

# Custom functions

```{r}
my_invgamma = function(x, nu0, sigma0){
  a = nu0/2
  b = a*sigma0
  b^a/gamma(a) * (1/x)^(a+1) * exp(-b/x)
}

```




# Simulate data (d=2)

Inizio con un caso semplice, $d=2$, per capire se la formula teorica e quella pratica mi danno risultati simili
```{r}

#1) Per prima cosa, estraggo un singolo valore per ogni giocatore in ogni stagione. Lo faccio estraendo da una mistura
n = 100
d = 2                         # number of seasons
K = 7                         # number of global clusters
mu = c(-4,-2 ,-2,0  ,2  ,2,4)      # vectors of means
sd = sqrt(c(1 ,0.5, 1,0.5,0.5,1,1))   # vector of sd
mix_probs = matrix(c(0.2,0.2,0,0.2,0.2,0,0.2,
                     0.25,0,0.25,0,0,0.25,0.25,
                     0.2,0.2,0,0.2,0.2,0,0.2,
                     0.2,0,0,0.6,0,0,0.2,
                     0,0,0,0.75,0,0.25,0),
                   nrow = d, ncol = K, byrow = T)

seed = 1234
set.seed(seed)
lambda_s = c(4,4,2.5,1.5,1.5)
N_ji = unlist(lapply( as.list(lambda_s), FUN = function(x){rpois(n = n, lambda = x)} ))
N_ji = matrix(N_ji,nrow = d, ncol = n, byrow = T )
N_ji = N_ji + 1
zeros = apply(N_ji, 1, function(N_j){sum(N_j == 0)})
n_j = rep(n,d) - zeros

genD = simulate_data(d = d, K = K, p = mix_probs, mu = mu, sd = sd, n_j = n_j, seed = seed)
real_partition = genD$real_partition

# creo un piccolo tibble che mi definisce nomi, stagioni e cluster vero
names = c()
SeasonNumber = c()
for(j in 1:d){
  names = c(names, seq(1,n_j[j]))
  SeasonNumber = c(SeasonNumber, rep(j,n_j[j]))
}

data_small = tibble( ID = names,
                     SeasonNumber = SeasonNumber,
                     TrueClustering = real_partition )

# ora riempio la struttura di dati vera e propria
data = tibble( "ID" = factor(), 
               "SeasonNumber" = factor(), 
               "Result" = numeric(),
               "t_ji" = numeric(),
               "TrueClustering" = factor() ) 

set.seed(seed)
for(h in 1:nrow(data_small)){
  j = data_small$SeasonNumber[h]
  i = data_small$ID[h]
  m = data_small$TrueClustering[h]
  Result = rnorm(n = N_ji[j,i], mean = mu[m], sd = sd[m])
  t_ji   = j - 0.5 + rnorm(n = N_ji[j,i], mean = 0, sd = 1/5)

  temp = tibble( "ID" = as.factor( rep(i,N_ji[j,i]) ), 
                 "SeasonNumber" = as.factor( rep(j,N_ji[j,i]) ), 
                 "Result" = Result,
                 "t_ji" = t_ji,
                 "TrueClustering" = as.factor( rep(m,N_ji[j,i]) ) ) 
  data = data %>% rbind(temp)
}

```

```{r}
mycol_trueclust = hcl.colors(n=K,palette = "Zissou1")
cols = data$TrueClustering
levels(cols) = mycol_trueclust
cols = as.character(cols)


seasons = 1:d

par(mar = c(4,4,2,1))
plot( x = data$t_ji, 
      y = data$Result,
      ylab = "Result", xlab = "Season",
      pch = 16, cex = 0.5, col = cols)
abline(v = seasons, lty = 2, col = "grey45", lwd = 1)
```

### Plot istogrammi (no covariate)
```{r}
mycol_trueclust = hcl.colors(n=K,palette = "Zissou1")
for(j in 1:d){
  plot(0,0,main = paste0("Season ",j),xlab = "Result", type = "n", xlim = range(data$Result), ylim = c(0,1))
  for(k in 1:K){
      res = data %>% filter(SeasonNumber == j) %>% filter(TrueClustering == k) %>% pull(Result)
      if(length(res)>0)
        hist(res, freq = FALSE, nclass = "fd", col=mycol_trueclust[k], add = T)
  }

}

```


## Hyperparameters 

$P_0$
```{r}
Res_range = range( data$Result )
R = Res_range[2] - Res_range[1]
mu0 = mean(data$Result) # should be 0
k0  = 1/R^2
nu0 = 10
sigma0 = 10#*(100*R/1)
c("mu0"=mu0,"k0"=k0,"nu0"=nu0,"sigma0"=sigma0)

scale = sqrt( (k0 + 1)/(k0) * sigma0 )
mean_marginal = mu0
var_marginal  = nu0/(nu0-2) * scale^2

mean_marginal
var_marginal
```
Plot di $P_0$
```{r}
xrange = c(-50,50)
l_grid = 1000
grid = seq(xrange[1],xrange[2],length.out = l_grid)
   
#par(mfrow = c(1,3), mar = c(2,2,2,1), bty = "l")
# Qua plotto la marginale
Prior_grid = GDFMM:::dnct(x = grid, n0 = nu0, mu0 = mu0, gamma0 = scale)
par(mar = c(2,2,2,1), bty = "l")
plot(1,1, xlim = xrange, ylim = c(0,max(Prior_grid)),
     type = "n",
     main = "Marginal data Density")
grid(lty = 1,lwd = 2,col = "gray90" )
points(x = na.omit(as.numeric(data$Result)), 
       y = rep(0, length(na.omit(as.numeric(data$Result)))), 
       ylim = c(0,0.1),
       pch = 16)
points(grid, Prior_grid, col = "black", lwd = 2, type = "l")
  
# Qua plotto la inverse-gamma
sigma_grid = seq(1e-5, 100, length.out = 1000)
par(mar = c(2,2,2,1), bty = "l")
plot(x = sigma_grid, y = my_invgamma(sigma_grid, nu0 = nu0, sigma0 = sigma0), 
     main = "Inverse-gamma prior Density", type = "l", lwd = 2, lty = 1)
grid(lty = 1,lwd = 2,col = "gray90" )
legend("topright", legend = c( "empricial var", 
                               paste0("InvGamma(",nu0/2,", ",round(sigma0*nu0/2, digits = 3),")")  ),
       lwd = 2, lty = c(2,1), col = c("grey45","black"))
 
# Qua invece plotto la marginale di mu
scale_mu = sqrt( sigma0/k0 )
Mar_mu_grid = GDFMM:::dnct(x = grid, n0 = nu0, mu0 = mu0, gamma0 = scale_mu)
par(mar = c(2,2,2,1), bty = "l")
plot(1,1, xlim = xrange, ylim = c(0,max(Mar_mu_grid)),
     type = "n",
     main = "Marginal mu Density")
grid(lty = 1,lwd = 2,col = "gray90" )
points(grid, Mar_mu_grid, col = "black", lwd = 2, type = "l")
points(x = na.omit(as.numeric(data$Result)), 
       y = rep(0, length(na.omit(as.numeric(data$Result)))), 
       ylim = c(0,0.1),
       pch = 16)

```

$(\Lambda,\gamma_1,\dots,\gamma_d)$ prior elicitation

- Caso 1: $\texttt{Exp_Lambda} = 20$, $\texttt{Var_Lambda} = 2$, $\texttt{gamma_guess} = 0.01$ -> tutto coincide con le curve teoriche
- Caso 2: $\texttt{Exp_Lambda} = 5$, $\texttt{Var_Lambda} = 1$, $\texttt{gamma_guess} = 0.01$ -> tutto coincide con le curve teoriche, ma ci vuole tanto per arrivare a convergenza
- Caso 3: $\texttt{Exp_Lambda} = 10$, $\texttt{Var_Lambda} = 1$, $\texttt{gamma_guess} = 1/200$ -> tutto coincide con le curve teoriche, ma ci vuole tanto per arrivare a convergenza
```{r}
Exp_Lambda   =  10
Var_Lambda   =  1
gamma_guess  =  1/200
Lambda_guess = Exp_Lambda

b_lambda = Exp_Lambda/Var_Lambda
a_lambda = Exp_Lambda * b_lambda

a_gamma = a_lambda/d
b_gamma = a_gamma / (gamma_guess * Lambda_guess) 

# plot
lambda_prior = rgamma(n=10000, shape = a_lambda, rate = b_lambda)
gamma_mar_prior = rgamma(n=10000, shape = a_gamma, rate = lambda_prior*b_gamma)
par(mar = c(2,2,2,1), bty = "l")
plot(density(gamma_mar_prior), lwd = 2, main = "Marginal for gamma", ylab = " ")

# cat("\n quantile for L(gamma) (MC estimate) \n")
# quantile(gamma_mar_prior, probs = c(0.5, 0.95, 0.99))

grid_lambda = seq(1e-8,100,length.out = 10000)
par(mar = c(2,2,2,1), bty = "l")
plot(grid_lambda, dgamma(grid_lambda, shape = a_lambda, rate = b_lambda), 
     lwd = 2, lty = 1, type = "l", main = "prior for lambda", ylab = " ")

```

## Theroretical number of clusters

Fixing $\gamma_1,\dots,\gamma_d$ as well as $\Lambda$
```{r}
gamma_mean = rep( (a_gamma/b_gamma) * b_lambda/(a_lambda - 1) , d)
lambda_mean = a_lambda/b_lambda
Kmax   = 20
pk = rep(0,Kmax)
for(k in 1:Kmax){
  #cat("\n k = ",k,"\n")
  pk[k] = p_distinct_prior(k = k, n_j = n_j, gamma = gamma_mean, prior = "Poisson", 
                           lambda = lambda_mean, Max_iter = 100)
  #cat("\n sum(pk) = ",sum(pk),"\n")
}

cat("\n sum(pk) = ",sum(pk),"\n")
plot(pk, type = "h", pch = 16, lty = 1, lwd = 2, xaxt = "n", xlab = "K")
mtext(text = as.character(1:20), side = 1, at = 1:20)
```


## Run 


### Initial values

Qui invece che prendere tutte le osservazioni prendo solo quella media
```{r}
data_med4season = data %>% group_by(ID,SeasonNumber) %>% 
                                    mutate(MedResult = mean(Result)) %>%
                                    select(ID,SeasonNumber,Result, MedResult,t_ji) %>%
                                    distinct(ID,SeasonNumber, .keep_all = TRUE) %>% 
                                    ungroup() %>% arrange(SeasonNumber)

data_med4season
```

```{r}
Ncenters = 30
ymedian = data_med4season %>% pull(MedResult)
Kmeans0 = kmeans(x = ymedian, centers = Ncenters, iter.max = 50, nstart = 10 )
KmeansCl = Kmeans0$cluster
centers = Kmeans0$centers
data_med4season = data_med4season %>% cbind("Kmeans" = KmeansCl)
```

Plot solo dei valori medi
```{r}

mycol_clus = hcl.colors(n = length(table(KmeansCl)), palette = "Temps")
cols = as.factor(data_med4season$Kmeans)
levels(cols) = mycol_clus
cols = as.character(cols)

seasons = 1:d
par(mar = c(4,4,2,1))
plot( x = data_med4season$t_ji, 
      y = data_med4season$MedResult,
      ylab = "Result", xlab = "Season",
      pch = 16, cex = 0.5, col = cols)
abline(v = seasons, lty = 2, col = "grey45", lwd = 1)
#abline(h = centers, lty = 2, col = "black", lwd = 0.1)
```
Plot di tutti i valori
```{r}
data_with_init = data %>% left_join(data_med4season %>% 
                                     select("ID","SeasonNumber","MedResult","Kmeans"), 
                                     by = c("ID","SeasonNumber"))

mycol_clus = hcl.colors(n = length(table(KmeansCl)), palette = "Temps")
cols = as.factor(data_with_init$Kmeans)
levels(cols) = mycol_clus
cols = as.character(cols)

seasons = 1:d
par(mar = c(4,4,2,1))
plot( x = data_with_init$t_ji, 
      y = data_with_init$Result,
      ylab = "Result", xlab = "Season",
      pch = 16, cex = 0.5, col = cols)
abline(v = seasons, lty = 2, col = "grey45", lwd = 1)

```



### Setup
Leggo i dati nel modo in cui poi devono essere inseriti

```{r}

dt = input_handle(data_with_init[,c(1:3,7)], intercept = FALSE)

#load("dt_d19_data51415.Rdat")
#load("dt_d19_data51415_age.Rdat")
n = dt$n
d = dt$d
r = dt$r
n_j = dt$n_j

#save(dt, file = "dt_d19_data51415_age.Rdat")
#save(dt, file = "dt_d19_data51415.Rdat")
#View(dt)
n;d;r;sum(n_j);sum(dt$N_ji)

```




```{r}
niter  <-  50000
burnin <-  1
thin   <-    1


# initial values
beta0 = rep(-2,dt$r)
Sigma0 = diag(dt$r)

Lambda0 = Exp_Lambda
gamma0 = rep(0.25,d)#rep(0.025,d)#1/n_j # per ora il valore magico è 0.025
Mstar0 = 3

cluster_mean = data_med4season %>% group_by(Kmeans) %>% 
                summarise(ClusterMean = mean(Result)) %>% ungroup() %>% pull(ClusterMean)
cluster_var  = data_med4season %>% group_by(Kmeans) %>% 
                summarise(ClusterVar = var(Result)) %>% ungroup() %>% pull(ClusterVar)
initial_partition = unlist(unlist(dt$initialPartition))


option = set_options( "mu0" = mu0,"sigma0"= sigma0, "k0"= k0, "nu0"=nu0, 
                      "Adapt_MH_hyp2" = 0.234, "Adapt_MH_var0"=0.1,
                      "proposal_Mstar" = 1,
                      "Lambda0" = Lambda0, "gamma0" = gamma0, "Mstar0" = Mstar0,
                      "beta0" = beta0, "Sigma0" = Sigma0,
                      "alpha_gamma" = a_gamma, "beta_gamma" = b_gamma, 
                      "alpha_lambda" = a_lambda, "beta_lambda" = b_lambda,
                      "init_mean_cluster" = c(centers, rep(0,Mstar0)), 
                      "init_var_cluster" = c(cluster_var, rep(1,Mstar0)), 
                      "partition" = initial_partition,
                      "IncludeCovariates" = FALSE,
                      "UseData" = FALSE,
                      "UpdateU" = T, "UpdateM" = T, "UpdateGamma" = T, 
                      "UpdateS" = T, "UpdateTau" = T, "UpdateLambda" = T,
                      "UpdateBeta" = F )

prior = "Normal-InvGamma"


```


```{r}
GDFMM = ConditionalSampler(dt[1:11], niter, burnin, thin, seed = 123, option = option, FixPartition = F,
                           P0.prior = prior, algorithm = "Neal2")
```


### Chains
```{r, echo = F}
if(option$UpdateLambda){
  #Lambda
  plot(GDFMM$lambda, type = 'l', main = expression(Lambda))
  hist(GDFMM$lambda, main = expression(Lambda))
}


if(option$UpdateM){
  # Mstar
  par(bty = "l")
  plot(GDFMM$Mstar, type = 'l', main = "Mstar")
  #acf(GDFMM$Mstar)
}


if(option$UpdateGamma){
  # gamma
  #par(mfrow = c(4,5))
  for(j in 1:d){
    plot(GDFMM$gamma[j,], type = 'l', main = paste0(expression(gamma), "_",j))
  }
  
  # 
  # par(mfrow = c(1,d), mar = c(2,2,1,1))
  # for(j in 1:d){
  #   acf(GDFMM$gamma[j,], main = paste0("ACF - ",expression(gamma), "_",j))
  # }
}



# U
# par(mfrow = c(1,d))
for(j in 1:d){
  plot(GDFMM$U[j,], type = 'l', main = paste0("U_",j))
}

# K
par(mfrow = c(1,1), bty = "l")
plot(GDFMM$K, type = 'l', main = "K")

par(mfrow = c(1,1), bty = "l")
barplot(table(GDFMM$K), main = "Hist - K")

# sigma (solo per il caso con prior Normal)
if(prior == "Normal"){
  sigma = unlist(lapply(GDFMM$sigma, FUN = function(sigma_it){sigma_it[1]}))
  par(mfrow = c(1,2), bty = "l")
  plot(sigma, type = 'l', main = "sigma^2 (variance) - traceplot")
  plot(density(sigma), main = "sigma^2 (variance) - density")  
}


```



## Confronto
```{r}
pk_MCMC = table(GDFMM$K[(niter/2) : niter])/ length((niter/2) : niter)
names(pk_MCMC) = paste0(names(pk_MCMC),".15")
pm_MCMC = table(GDFMM$K[(niter/2) : niter] + GDFMM$Mstar[(niter/2) : niter])/ length((niter/2) : niter)
names(pm_MCMC) = paste0(names(pm_MCMC),".05")
grid_lambda = seq(1e-8,20,length.out = 10000)

B = 10000
lambda_prior = rgamma(n=B, shape = a_lambda, rate = b_lambda)
M_mar_prior = rpois(n=B, lambda = lambda_prior)+1



par(mar = c(2,2,2,1), bty = "l")
plot(grid_lambda, dgamma(grid_lambda, shape = a_lambda, rate = b_lambda), ylim = c(0,1),
     lwd = 2, lty = 1, type = "l", main = "Prior comparison", ylab = " ", col = "blue")
points(pk_MCMC, type = "h", col = "black", xlab = "K")
points(pk, type = "h", pch = 16, lty = 1, lwd = 2, xaxt = "n", xlab = "K", col = "lightblue4")
points(pm_MCMC, type = "h", col = "orange", xlab = "K")
points(table(M_mar_prior)/B, type = "h", col = "red", xlab = "M")
legend("topright", c("K - Exact","K - MCMC","Lambda","M - MC", "M - MCMC"), 
       col = c("lightblue4","black","blue","red","orange"), pch = 16)

```




# Simulate data (d=15)

Ora simulo un caso in cui $d=15$ in cui posso solo usare la stima MCMC
```{r}

#1) Per prima cosa, estraggo un singolo valore per ogni giocatore in ogni stagione. Lo faccio estraendo da una mistura
n = 100
d = 15                         # number of seasons
K = 7                         # number of global clusters
mu = c(-4,-2 ,-2,0  ,2  ,2,4)      # vectors of means
sd = sqrt(c(1 ,0.5, 1,0.5,0.5,1,1))   # vector of sd
mix_probs = matrix(c(0.2,0.2,0,0.2,0.2,0,0.2,
                     0.25,0,0.25,0,0,0.25,0.25,
                     0.2,0.2,0,0.2,0.2,0,0.2,
                     0.2,0,0,0.6,0,0,0.2,
                     0,0,0,0.75,0,0.25,0),
                   nrow = d, ncol = K, byrow = T)

seed = 1234
set.seed(seed)
lambda_s = c(4,4,2.5,1.5,1.5)
N_ji = unlist(lapply( as.list(lambda_s), FUN = function(x){rpois(n = n, lambda = x)} ))
N_ji = matrix(N_ji,nrow = d, ncol = n, byrow = T )
N_ji = N_ji + 1
zeros = apply(N_ji, 1, function(N_j){sum(N_j == 0)})
n_j = rep(n,d) - zeros

genD = simulate_data(d = d, K = K, p = mix_probs, mu = mu, sd = sd, n_j = n_j, seed = seed)
real_partition = genD$real_partition

# creo un piccolo tibble che mi definisce nomi, stagioni e cluster vero
names = c()
SeasonNumber = c()
for(j in 1:d){
  names = c(names, seq(1,n_j[j]))
  SeasonNumber = c(SeasonNumber, rep(j,n_j[j]))
}

data_small = tibble( ID = names,
                     SeasonNumber = SeasonNumber,
                     TrueClustering = real_partition )

# ora riempio la struttura di dati vera e propria
data = tibble( "ID" = factor(), 
               "SeasonNumber" = factor(), 
               "Result" = numeric(),
               "t_ji" = numeric(),
               "TrueClustering" = factor() ) 

set.seed(seed)
for(h in 1:nrow(data_small)){
  j = data_small$SeasonNumber[h]
  i = data_small$ID[h]
  m = data_small$TrueClustering[h]
  Result = rnorm(n = N_ji[j,i], mean = mu[m], sd = sd[m])
  t_ji   = j - 0.5 + rnorm(n = N_ji[j,i], mean = 0, sd = 1/5)

  temp = tibble( "ID" = as.factor( rep(i,N_ji[j,i]) ), 
                 "SeasonNumber" = as.factor( rep(j,N_ji[j,i]) ), 
                 "Result" = Result,
                 "t_ji" = t_ji,
                 "TrueClustering" = as.factor( rep(m,N_ji[j,i]) ) ) 
  data = data %>% rbind(temp)
}

```

```{r}
mycol_trueclust = hcl.colors(n=K,palette = "Zissou1")
cols = data$TrueClustering
levels(cols) = mycol_trueclust
cols = as.character(cols)


seasons = 1:d

par(mar = c(4,4,2,1))
plot( x = data$t_ji, 
      y = data$Result,
      ylab = "Result", xlab = "Season",
      pch = 16, cex = 0.5, col = cols)
abline(v = seasons, lty = 2, col = "grey45", lwd = 1)
```



## Hyperparameters 

$P_0$
```{r}
Res_range = range( data$Result )
R = Res_range[2] - Res_range[1]
mu0 = mean(data$Result) # should be 0
k0  = 1/R^2
nu0 = 10
sigma0 = 10#*(100*R/1)
c("mu0"=mu0,"k0"=k0,"nu0"=nu0,"sigma0"=sigma0)

scale = sqrt( (k0 + 1)/(k0) * sigma0 )
mean_marginal = mu0
var_marginal  = nu0/(nu0-2) * scale^2

mean_marginal
var_marginal
```
Plot di $P_0$
```{r}
xrange = c(-50,50)
l_grid = 1000
grid = seq(xrange[1],xrange[2],length.out = l_grid)
   
#par(mfrow = c(1,3), mar = c(2,2,2,1), bty = "l")
# Qua plotto la marginale
Prior_grid = GDFMM:::dnct(x = grid, n0 = nu0, mu0 = mu0, gamma0 = scale)
par(mar = c(2,2,2,1), bty = "l")
plot(1,1, xlim = xrange, ylim = c(0,max(Prior_grid)),
     type = "n",
     main = "Marginal data Density")
grid(lty = 1,lwd = 2,col = "gray90" )
points(x = na.omit(as.numeric(data$Result)), 
       y = rep(0, length(na.omit(as.numeric(data$Result)))), 
       ylim = c(0,0.1),
       pch = 16)
points(grid, Prior_grid, col = "black", lwd = 2, type = "l")
  
# Qua plotto la inverse-gamma
sigma_grid = seq(1e-5, 100, length.out = 1000)
par(mar = c(2,2,2,1), bty = "l")
plot(x = sigma_grid, y = my_invgamma(sigma_grid, nu0 = nu0, sigma0 = sigma0), 
     main = "Inverse-gamma prior Density", type = "l", lwd = 2, lty = 1)
grid(lty = 1,lwd = 2,col = "gray90" )
legend("topright", legend = c( "empricial var", 
                               paste0("InvGamma(",nu0/2,", ",round(sigma0*nu0/2, digits = 3),")")  ),
       lwd = 2, lty = c(2,1), col = c("grey45","black"))
 
# Qua invece plotto la marginale di mu
scale_mu = sqrt( sigma0/k0 )
Mar_mu_grid = GDFMM:::dnct(x = grid, n0 = nu0, mu0 = mu0, gamma0 = scale_mu)
par(mar = c(2,2,2,1), bty = "l")
plot(1,1, xlim = xrange, ylim = c(0,max(Mar_mu_grid)),
     type = "n",
     main = "Marginal mu Density")
grid(lty = 1,lwd = 2,col = "gray90" )
points(grid, Mar_mu_grid, col = "black", lwd = 2, type = "l")
points(x = na.omit(as.numeric(data$Result)), 
       y = rep(0, length(na.omit(as.numeric(data$Result)))), 
       ylim = c(0,0.1),
       pch = 16)

```

$(\Lambda,\gamma_1,\dots,\gamma_d)$ prior elicitation:

- Caso 1: $\texttt{Exp_Lambda} = 25$, $\texttt{Var_Lambda} = 2$, $\texttt{gamma_guess} = 0.01$ -> $M$ coincide con curva teorica, $K$ è sensato
- Caso 2: $\texttt{Exp_Lambda} = 25$, $\texttt{Var_Lambda} = 2$, $\texttt{gamma_guess} = 1/200$ -> $M$ coincide con curva teorica, $K$ è sensato
- Caso 3: $\texttt{Exp_Lambda} = 5$, $\texttt{Var_Lambda} = 1$, $\texttt{gamma_guess} = 0.01$ -> cosi non va molto bene, $K+M^*$ nel MCMC sovrastima $M$
- Caso 4: $\Lambda = 5$ fisso, $\gamma = 1e-5$ tutti uguali e fissi --> cosi non va bene, $K+M^*$ nel MCMC sovrastima $M$
```{r}
Exp_Lambda   =  25
Var_Lambda   =  2
gamma_guess  =  0.1
Lambda_guess = Exp_Lambda

b_lambda = Exp_Lambda/Var_Lambda
a_lambda = Exp_Lambda * b_lambda

a_gamma = a_lambda/d
b_gamma = a_gamma / (gamma_guess * Lambda_guess) 

# plot
lambda_prior = rgamma(n=10000, shape = a_lambda, rate = b_lambda)
gamma_mar_prior = rgamma(n=10000, shape = a_gamma, rate = lambda_prior*b_gamma)
par(mar = c(2,2,2,1), bty = "l")
plot(density(gamma_mar_prior), lwd = 2, main = "Marginal for gamma", ylab = " ")

# cat("\n quantile for L(gamma) (MC estimate) \n")
# quantile(gamma_mar_prior, probs = c(0.5, 0.95, 0.99))

grid_lambda = seq(1e-8,100,length.out = 10000)
par(mar = c(2,2,2,1), bty = "l")
plot(grid_lambda, dgamma(grid_lambda, shape = a_lambda, rate = b_lambda), 
     lwd = 2, lty = 1, type = "l", main = "prior for lambda", ylab = " ")

```


## Run 


### Initial values

Qui invece che prendere tutte le osservazioni prendo solo quella media
```{r}
data_med4season = data %>% group_by(ID,SeasonNumber) %>% 
                                    mutate(MedResult = mean(Result)) %>%
                                    select(ID,SeasonNumber,Result, MedResult,t_ji) %>%
                                    distinct(ID,SeasonNumber, .keep_all = TRUE) %>% 
                                    ungroup() %>% arrange(SeasonNumber)

data_med4season
```

```{r}
Ncenters = 5
ymedian = data_med4season %>% pull(MedResult)
Kmeans0 = kmeans(x = ymedian, centers = Ncenters, iter.max = 50, nstart = 10 )
KmeansCl = Kmeans0$cluster
centers = Kmeans0$centers
data_med4season = data_med4season %>% cbind("Kmeans" = KmeansCl)
```

Plot di tutti i valori
```{r}
data_with_init = data %>% left_join(data_med4season %>% 
                                     select("ID","SeasonNumber","MedResult","Kmeans"), 
                                     by = c("ID","SeasonNumber"))

mycol_clus = hcl.colors(n = length(table(KmeansCl)), palette = "Temps")
cols = as.factor(data_with_init$Kmeans)
levels(cols) = mycol_clus
cols = as.character(cols)

seasons = 1:d
par(mar = c(4,4,2,1))
plot( x = data_with_init$t_ji, 
      y = data_with_init$Result,
      ylab = "Result", xlab = "Season",
      pch = 16, cex = 0.5, col = cols)
abline(v = seasons, lty = 2, col = "grey45", lwd = 1)

```



### Setup
Leggo i dati nel modo in cui poi devono essere inseriti

```{r}

dt = input_handle(data_with_init[,c(1:3,7)], intercept = FALSE)

#load("dt_d19_data51415.Rdat")
#load("dt_d19_data51415_age.Rdat")
n = dt$n
d = dt$d
r = dt$r
n_j = dt$n_j

#save(dt, file = "dt_d19_data51415_age.Rdat")
#save(dt, file = "dt_d19_data51415.Rdat")
#View(dt)
n;d;r;sum(n_j);sum(dt$N_ji)

```




```{r}
niter  <-  1000#0
burnin <-  1
thin   <-    1


# initial values
beta0 = rep(-2,dt$r)
Sigma0 = diag(dt$r)

Lambda0 = 5
gamma0 = rep(1,d)#rep(0.025,d)#1/n_j # per ora il valore magico è 0.025
Mstar0 = 4

cluster_mean = data_med4season %>% group_by(Kmeans) %>% 
                summarise(ClusterMean = mean(Result)) %>% ungroup() %>% pull(ClusterMean)
cluster_var  = data_med4season %>% group_by(Kmeans) %>% 
                summarise(ClusterVar = var(Result)) %>% ungroup() %>% pull(ClusterVar)
initial_partition = unlist(unlist(dt$initialPartition))


option = set_options( "mu0" = mu0,"sigma0"= sigma0, "k0"= k0, "nu0"=nu0, 
                      "Adapt_MH_hyp2" = 0.234, "Adapt_MH_var0"=0.1,
                      "proposal_Mstar" = 1,
                      "Lambda0" = Lambda0, "gamma0" = gamma0, "Mstar0" = Mstar0,
                      "beta0" = beta0, "Sigma0" = Sigma0,
                      "alpha_gamma" = a_gamma, "beta_gamma" = b_gamma, 
                      "alpha_lambda" = a_lambda, "beta_lambda" = b_lambda,
                      "init_mean_cluster" = c(centers, rep(0,Mstar0)), 
                      "init_var_cluster" = c(cluster_var, rep(1,Mstar0)), 
                      "partition" = initial_partition,
                      "IncludeCovariates" = FALSE,
                      "UseData" = FALSE,
                      "UpdateU" = T, "UpdateM" = T, "UpdateGamma" = T, 
                      "UpdateS" = T, "UpdateTau" = T, "UpdateLambda" = T,
                      "UpdateBeta" = F )

prior = "Normal-InvGamma"


```


```{r}
GDFMM = ConditionalSampler(dt[1:11], niter, burnin, thin, seed = 123, option = option, FixPartition = F,
                           P0.prior = prior, algorithm = "Neal2")
```


### Chains
```{r, echo = F}
if(option$UpdateLambda){
  #Lambda
  plot(GDFMM$lambda, type = 'l', main = expression(Lambda))
  hist(GDFMM$lambda, main = expression(Lambda))

}


if(option$UpdateM){
  # Mstar
  par(bty = "l")
  plot(GDFMM$Mstar, type = 'l', main = "Mstar")
  #acf(GDFMM$Mstar)
}


if(option$UpdateGamma){
  # gamma
  #par(mfrow = c(4,5))
  for(j in 1:d){
    plot(GDFMM$gamma[j,], type = 'l', main = paste0(expression(gamma), "_",j))
  }
  
  # 
  # par(mfrow = c(1,d), mar = c(2,2,1,1))
  # for(j in 1:d){
  #   acf(GDFMM$gamma[j,], main = paste0("ACF - ",expression(gamma), "_",j))
  # }
}


# K
par(mfrow = c(1,1), bty = "l")
plot(GDFMM$K, type = 'l', main = "K")

par(mfrow = c(1,1), bty = "l")
barplot(table(GDFMM$K), main = "Hist - K")



```

Debugging
```{r}
# Plot U_j
for(j in 1:d)
  plot(GDFMM$U[j,], type = 'l', main = paste0(expression(U), "_",j))

# Plot 1/(1+U_j)
for(j in 1:d)
  plot( 1/(GDFMM$U[j,]+1), type = 'l', main = paste0("1/(",expression(U), "_",j,"+1)"))


# S
S = GDFMM$S
S_it = S[[5000]]
S_it = t(apply(S_it, 1, FUN = function(x){x/sum(x)}))
S_it[,33]

Part_it = GDFMM$Partition[8000,]
table(Part_it)

Local_Clustering = list("list", length = d)
idx_start = c(1,cumsum(n_j)[1:(d-1)]+1)
idx_end = cumsum(n_j)
Kj = matrix(0,nrow = niter, ncol = d)
for(j in 1:d){
  Local_Clustering[[j]] = GDFMM$Partition[ , idx_start[j]:idx_end[j] ]
  Kj[,j] = apply(Local_Clustering[[j]], 1, FUN = function(Part_it){length(table(Part_it))})
  par(mfrow = c(1,2), bty = "l")
  plot(Kj[,j], type = 'l', main = paste0("Local K in Season ",j))
  barplot(table(Kj[,j]), main = paste0("Local K in Season ",j))

}
```


```{r}
par(mar = c(2,2,2,1), bty = "l")
plot(density(GDFMM$lambda), lwd = 2, main = paste0("Prior vs Posterior - Lambda"), type = "l",
     ylab = " ", xlim = c(0,25), col = "red")
points(grid_lambda, dgamma(grid_lambda, shape = a_lambda, rate = b_lambda), 
   lwd = 2, lty = 1, type = "l", main = "prior for lambda", ylab = " ")


# gamma
par(mar = c(2,2,2,1), bty = "l")
plot(density(gamma_mar_prior), lwd = 2, main = paste0("Prior vs Posterior - gamma_",1), type = "l",
     ylab = " ", xlim = c(0,5), col = "red")
lines(density(GDFMM$gamma[1,]), lwd = 2)
legend("topright",c("exact","MCMC"),col=c("red","black"),pch = 16)
```



## Final plot
```{r}
take_iteration = seq(niter/2,niter,by=5)
nit = length(take_iteration)

pk_MCMC = table(GDFMM$K[take_iteration])/ nit
names(pk_MCMC) = paste0(names(pk_MCMC),".35")
pm_MCMC = table(GDFMM$K[take_iteration] + GDFMM$Mstar[take_iteration])/ nit
names(pm_MCMC) = paste0(names(pm_MCMC),".15")
grid_lambda = seq(1e-8,20,length.out = 10000)

B = 10000
lambda_prior = 5#rgamma(n=B, shape = a_lambda, rate = b_lambda)
M_mar_prior = rpois(n=B, lambda = lambda_prior)+1



par(mar = c(2,2,2,1), bty = "l")
plot(grid_lambda, dgamma(grid_lambda, shape = a_lambda, rate = b_lambda), ylim = c(0,0.4),
     lwd = 2, lty = 1, type = "l", main = "Prior comparison", ylab = " ", col = "blue")
points(pk_MCMC, type = "h", col = "black", xlab = "K")
points(pm_MCMC, type = "h", col = "orange", xlab = "K")
points(table(M_mar_prior)/B, type = "h", col = "red", xlab = "M")
legend("topright", c("K - MCMC","Lambda","M - MC", "M - MCMC"), 
       col = c("black","blue","red","orange"), pch = 16)
```


# Lambda piccolo

Guardo meglio un caso semplice in cui $\Lambda$ è piccolo. In questo caso, non riesco a trovare valori ragionevoli di $\gamma$ per cui la distribuzione di $K$ sia diversa da quella di $M$. Infatti le due coincidono, il che implica che $M^*$ sia sempre nullo

```{r}
d = 15
n_j = rep(100,d)
gamma_mean = rep(1,d)
lambda_mean = 5
Kmax   = 10
pk = rep(0,Kmax)
for(k in 1:Kmax){
  cat("\n k = ",k,"\n")
  pk[k] = p_distinct_prior(k = k, n_j = n_j, gamma = gamma_mean, prior = "Poisson", 
                           lambda = lambda_mean, Max_iter = 100)
  cat("\n sum(pk) = ",sum(pk),"\n")
}

cat("\n sum(pk) = ",sum(pk),"\n")

```

```{r}

B = 10000
lambda_prior = 5
M_mar_prior = rpois(n=B, lambda = lambda_prior)+1
Exact_M = table(M_mar_prior)/B
names(Exact_M) = paste0(names(Exact_M),".15")

par( mar = c(2,2,2,1), bty = "l")
plot(pk, type = "h", col = "lightblue4", xlab = "K",xaxt = "n",
     lwd = 2, main = "Exact K (Lambda=5,gamma=1) vs Exact M")
points(Exact_M, type = "h", col = "red", xlab = "M", main = "Exact M")
mtext(text = as.character(1:20), side = 1, at = 1:20)
```

# Esperimento dati veri

Qua carico tutti i dati a disposizione
```{r}
#.data_aligned = read.csv("Shotput_longformat_preproc_all.csv", row.names=1)
data_aligned = read.csv("Shotput_longformat_preproc_nofew50.csv", row.names=1)
data_aligned = as_tibble(data_aligned) %>% mutate(ID = as.factor(ID),
                                                 SeasonNumber = as.factor(SeasonNumber),
                                                 Gender = as.factor(Gender),
                                                 Environment = as.factor(Environment)) %>%
                                      select(ID,SeasonNumber,Result,
                                             Gender,Environment,Age,AgeEntrance,
                                             Days,t_ji)
data_aligned

n = nrow(data_aligned %>% distinct(ID))
```

Seleziono solo pochi dati e solo un numero ristretto di stagioni

L'atleta con ID 76011 è quello che nella stagione 3 ha fatto un punteggio ridicolo (1.48). Però ha comunque giocato molte partite e molte stagioni, posso decidere se togliere solo quella stagione (però poi ho un buco) oppure togliere lui completamente
```{r}
selectIDs = 1:n#c(1:145)
d = 15
IDs  = data_aligned %>% distinct(ID) %>% pull(ID)
data_longform_input = data_aligned %>%
                      filter(ID %in% IDs[selectIDs]) %>%
                      filter(SeasonNumber %in% as.factor(1:d)) %>%
                      filter(ID != "76011") %>%
                      select(ID,SeasonNumber,Result,Gender,Environment,Age,AgeEntrance,Days,t_ji)
```

Trasformo i dati - Centro i dati e le covariate quantitative

```{r}
data_longform_input$Result      = data_longform_input$Result  
data_longform_input$Result      = data_longform_input$Result      - mean(data_longform_input$Result)
data_longform_input$Age         = data_longform_input$Age         - mean(data_longform_input$Age)
data_longform_input$AgeEntrance = data_longform_input$AgeEntrance - mean(data_longform_input$AgeEntrance)


```


## Plot 

```{r}
mycol_gender = c("deepskyblue3", "palevioletred1")
cols = data_longform_input$Gender
levels(cols) = mycol_gender
cols = as.character(cols)

seasons = 1:d

par(mar = c(4,4,2,1))
plot( x = data_longform_input$t_ji, 
      y = data_longform_input$Result,
      ylab = "Result", xlab = "Season",
      pch = 16, cex = 0.4, col = cols)
abline(v = seasons, lty = 2, col = "grey45", lwd = 1)
```



## Hyperparameters (current solution)


```{r}
Res_range = range( data_longform_input$Result )
R = Res_range[2] - Res_range[1]
mu0 = mean(data_longform_input$Result) # should be 0
k0  = 10/R^2
nu0 = 10
sigma0 = 10
c("mu0"=mu0,"k0"=k0,"nu0"=nu0,"sigma0"=sigma0)

scale = sqrt( (k0 + 1)/(k0) * sigma0 )
mean_marginal = mu0
var_marginal  = nu0/(nu0-2) * scale^2

mean_marginal
var_marginal
```


$(\Lambda,\gamma_1,\dots,\gamma_d)$ prior elicitation
```{r}
Exp_Lambda   =  25
Var_Lambda   =  3
gamma_guess  =  0.01
Lambda_guess = Exp_Lambda

b_lambda = Exp_Lambda/Var_Lambda
a_lambda = Exp_Lambda * b_lambda

a_gamma = a_lambda/d
b_gamma = a_gamma / (gamma_guess * Lambda_guess) 

# plot
lambda_prior = rgamma(n=10000, shape = a_lambda, rate = b_lambda)
gamma_mar_prior = rgamma(n=10000, shape = a_gamma, rate = lambda_prior*b_gamma)
par(mar = c(2,2,2,1), bty = "l")
plot(density(gamma_mar_prior), lwd = 2, main = "Marginal for gamma", ylab = " ")

# cat("\n quantile for L(gamma) (MC estimate) \n")
# quantile(gamma_mar_prior, probs = c(0.5, 0.95, 0.99))

grid_lambda = seq(1e-8,100,length.out = 10000)
par(mar = c(2,2,2,1), bty = "l")
plot(grid_lambda, dgamma(grid_lambda, shape = a_lambda, rate = b_lambda), 
     lwd = 2, lty = 1, type = "l", main = "prior for lambda", ylab = " ")

```


## Run 


### Initial values

Qui invece che prendere tutte le osservazioni prendo solo quella media
```{r}
data_med4season = data_longform_input %>% group_by(ID,SeasonNumber) %>% 
                                          mutate(MedResult = mean(Result)) %>%
                                          select(ID,SeasonNumber,Result, MedResult,
                                            Gender,Environment,Age,AgeEntrance,
                                            Days,t_ji) %>%
                                         distinct(ID,SeasonNumber, .keep_all = TRUE) %>% 
                                         ungroup() %>% arrange(SeasonNumber)

data_med4season
```

Con covariate, devo prima fare una regressione
```{r}
mycol_gender = c("deepskyblue3", "palevioletred1")
cols = data_med4season$Gender
levels(cols) = mycol_gender
cols = as.character(cols)
ymedian = data_med4season %>% pull(MedResult)
res = lm(Result ~ Gender, data = as.data.frame(data_med4season))$residuals
plot(res, pch = 16, col = cols, main = "Residuals", cex = 0.5)


Ncenters = 50
Kmeans0 = kmeans(x = res, centers = Ncenters, iter.max = 50, nstart = 10 )
KmeansCl = Kmeans0$cluster
centers = Kmeans0$centers
data_med4season = data_med4season %>% cbind("Kmeans" = KmeansCl)
```

Plot solo dei valori mediani
```{r}

mycol_clus = hcl.colors(n = length(table(KmeansCl)), palette = "Temps")
cols = as.factor(data_med4season$Kmeans)
levels(cols) = mycol_clus
cols = as.character(cols)

seasons = 1:d
par(mar = c(4,4,2,1))
plot( x = data_med4season$t_ji, 
      y = data_med4season$MedResult,
      ylab = "Result", xlab = "Season",
      pch = 16, cex = 0.5, col = cols)
abline(v = seasons, lty = 2, col = "grey45", lwd = 1)
#abline(h = centers, lty = 2, col = "black", lwd = 0.1)
```

Plot di tutti i valori
```{r}
data_with_init = data_longform_input %>% left_join(data_med4season %>% 
                                                     select("ID","SeasonNumber","MedResult","Kmeans"), 
                                                   by = c("ID","SeasonNumber"))

mycol_clus = hcl.colors(n = length(table(KmeansCl)), palette = "Temps")
cols = as.factor(data_with_init$Kmeans)
levels(cols) = mycol_clus
cols = as.character(cols)

seasons = 1:d
par(mar = c(4,4,2,1))
plot( x = data_with_init$t_ji, 
      y = data_with_init$Result,
      ylab = "Result", xlab = "Season",
      pch = 16, cex = 0.5, col = cols)
abline(v = seasons, lty = 2, col = "grey45", lwd = 1)

```



### Setup

Leggo i dati nel modo in cui poi devono essere inseriti

```{r}

dt = input_handle(data_with_init[,c(1:3,11)], intercept = FALSE)

n = dt$n
d = dt$d
r = dt$r
n_j = dt$n_j
#save(dt, file =  "dt_36084_cov.Rdat")
#View(dt)
n;d;r;sum(n_j);sum(dt$N_ji)
```

```{r}
niter  <-  40000
burnin <-  1
thin   <-    1


# initial values
beta0 = rep(-2,dt$r)
Sigma0 = diag(dt$r)

Lambda0 = Exp_Lambda
gamma0 = rep(0.25,d)#rep(0.025,d)#1/n_j # per ora il valore magico è 0.025
Mstar0 = 3

cluster_mean = data_med4season %>% group_by(Kmeans) %>% 
                summarise(ClusterMean = mean(Result)) %>% ungroup() %>% pull(ClusterMean)
cluster_var  = data_med4season %>% group_by(Kmeans) %>% 
                summarise(ClusterVar = var(Result)) %>% ungroup() %>% pull(ClusterVar)
initial_partition = unlist(unlist(dt$initialPartition))


option = set_options( "mu0" = mu0,"sigma0"= sigma0, "k0"= k0, "nu0"=nu0, 
                      "Adapt_MH_hyp2" = 0.234, "Adapt_MH_var0"=0.1,
                      "proposal_Mstar" = 1,
                      "Lambda0" = Lambda0, "gamma0" = gamma0, "Mstar0" = Mstar0,
                      "beta0" = beta0, "Sigma0" = Sigma0,
                      "alpha_gamma" = a_gamma, "beta_gamma" = b_gamma, 
                      "alpha_lambda" = a_lambda, "beta_lambda" = b_lambda,
                      "init_mean_cluster" = c(centers, rep(0,Mstar0)), 
                      "init_var_cluster" = c(cluster_var, rep(1,Mstar0)), 
                      "partition" = initial_partition,
                      "IncludeCovariates" = FALSE,
                      "UseData" = F,
                      "UpdateU" = T, "UpdateM" = T, "UpdateGamma" = T, 
                      "UpdateS" = T, "UpdateTau" = T, "UpdateLambda" = T,
                      "UpdateBeta" = F )

prior = "Normal-InvGamma"


```


```{r}
GDFMM = ConditionalSampler(dt[1:11], niter, burnin, thin, seed = 123, option = option, FixPartition = F,
                           P0.prior = prior, algorithm = "Neal2")
```

### Chains
```{r, echo = F}
if(option$UpdateLambda){
  #Lambda
  plot(GDFMM$lambda, type = 'l', main = expression(Lambda))
  hist(GDFMM$lambda, main = expression(Lambda))
}


if(option$UpdateM){
  # Mstar
  par(bty = "l")
  plot(GDFMM$Mstar, type = 'l', main = "Mstar")
  #acf(GDFMM$Mstar)
}


if(option$UpdateGamma){
  # gamma
  #par(mfrow = c(4,5))
  for(j in 1:d){
    plot(GDFMM$gamma[j,], type = 'l', main = paste0(expression(gamma), "_",j))
  }
  
  # 
  # par(mfrow = c(1,d), mar = c(2,2,1,1))
  # for(j in 1:d){
  #   acf(GDFMM$gamma[j,], main = paste0("ACF - ",expression(gamma), "_",j))
  # }
}



# U
# par(mfrow = c(1,d))
for(j in 1:d){
  plot(GDFMM$U[j,], type = 'l', main = paste0("U_",j))
}

# K
par(mfrow = c(1,1), bty = "l")
plot(GDFMM$K, type = 'l', main = "K")

par(mfrow = c(1,1), bty = "l")
barplot(table(GDFMM$K), main = "Hist - K")

# sigma (solo per il caso con prior Normal)
if(prior == "Normal"){
  sigma = unlist(lapply(GDFMM$sigma, FUN = function(sigma_it){sigma_it[1]}))
  par(mfrow = c(1,2), bty = "l")
  plot(sigma, type = 'l', main = "sigma^2 (variance) - traceplot")
  plot(density(sigma), main = "sigma^2 (variance) - density")  
}


```



## Final plot
```{r}
pk_MCMC = table(GDFMM$K[(niter/2) : niter])/ length((niter/2) : niter)
grid_lambda = seq(1e-8,60,length.out = 10000)

B = 10000
lambda_prior = rgamma(n=B, shape = a_lambda, rate = b_lambda)
M_mar_prior = rpois(n=B, lambda = lambda_prior)



par(mar = c(2,2,2,1), bty = "l")
plot(grid_lambda, dgamma(grid_lambda, shape = a_lambda, rate = b_lambda), 
     lwd = 2, lty = 1, type = "l", main = "Prior comparison", ylab = " ", col = "blue")
points(pk_MCMC, type = "h", col = "black", xlab = "K")
points(table(M_mar_prior)/B, type = "h", col = "red", xlab = "M")
legend("topright", c("K - MC","Lambda","M - MC"), col = c("black","blue","red"), pch = 16)

```


## Hyperparameters (gamma alto)

$P_0$ non la cambio, tanto non ha effetto a prior.

$(\Lambda,\gamma_1,\dots,\gamma_d)$ prior elicitation

Ho provato anche a mettere un valore più altro, tipo $1$, ma in questa caso non mixxa neanche a priori
```{r}
Exp_Lambda   =  25
Var_Lambda   =  3
gamma_guess  =  0.1 
Lambda_guess = Exp_Lambda

b_lambda = Exp_Lambda/Var_Lambda
a_lambda = Exp_Lambda * b_lambda

a_gamma = a_lambda/d
b_gamma = a_gamma / (gamma_guess * Lambda_guess) 

# plot
lambda_prior = rgamma(n=10000, shape = a_lambda, rate = b_lambda)
gamma_mar_prior = rgamma(n=10000, shape = a_gamma, rate = lambda_prior*b_gamma)
par(mar = c(2,2,2,1), bty = "l")
plot(density(gamma_mar_prior), lwd = 2, main = "Marginal for gamma", ylab = " ")

# cat("\n quantile for L(gamma) (MC estimate) \n")
# quantile(gamma_mar_prior, probs = c(0.5, 0.95, 0.99))

grid_lambda = seq(1e-8,100,length.out = 10000)
par(mar = c(2,2,2,1), bty = "l")
plot(grid_lambda, dgamma(grid_lambda, shape = a_lambda, rate = b_lambda), 
     lwd = 2, lty = 1, type = "l", main = "prior for lambda", ylab = " ")

```


## Run 

### Setup

```{r}
niter  <-  80000
burnin <-  1
thin   <-    1


# initial values
beta0 = rep(-2,dt$r)
Sigma0 = diag(dt$r)

Lambda0 = Exp_Lambda
gamma0 = rep(0.25,d)#rep(0.025,d)#1/n_j # per ora il valore magico è 0.025
Mstar0 = 3

cluster_mean = data_med4season %>% group_by(Kmeans) %>% 
                summarise(ClusterMean = mean(Result)) %>% ungroup() %>% pull(ClusterMean)
cluster_var  = data_med4season %>% group_by(Kmeans) %>% 
                summarise(ClusterVar = var(Result)) %>% ungroup() %>% pull(ClusterVar)
initial_partition = unlist(unlist(dt$initialPartition))


option = set_options( "mu0" = mu0,"sigma0"= sigma0, "k0"= k0, "nu0"=nu0, 
                      "Adapt_MH_hyp2" = 0.234, "Adapt_MH_var0"=0.1,
                      "proposal_Mstar" = 1,
                      "Lambda0" = Lambda0, "gamma0" = gamma0, "Mstar0" = Mstar0,
                      "beta0" = beta0, "Sigma0" = Sigma0,
                      "alpha_gamma" = a_gamma, "beta_gamma" = b_gamma, 
                      "alpha_lambda" = a_lambda, "beta_lambda" = b_lambda,
                      "init_mean_cluster" = c(centers, rep(0,Mstar0)), 
                      "init_var_cluster" = c(cluster_var, rep(1,Mstar0)), 
                      "partition" = initial_partition,
                      "IncludeCovariates" = FALSE,
                      "UseData" = F,
                      "UpdateU" = T, "UpdateM" = T, "UpdateGamma" = T, 
                      "UpdateS" = T, "UpdateTau" = T, "UpdateLambda" = T,
                      "UpdateBeta" = F )

prior = "Normal-InvGamma"


```


```{r}
GDFMM = ConditionalSampler(dt[1:11], niter, burnin, thin, seed = 123, option = option, FixPartition = F,
                           P0.prior = prior, algorithm = "Neal2")
```

### Chains
```{r, echo = F}
if(option$UpdateLambda){
  #Lambda
  plot(GDFMM$lambda, type = 'l', main = expression(Lambda))
  hist(GDFMM$lambda, main = expression(Lambda))
}


if(option$UpdateM){
  # Mstar
  par(bty = "l")
  plot(GDFMM$Mstar, type = 'l', main = "Mstar")
  #acf(GDFMM$Mstar)
}


if(option$UpdateGamma){
  # gamma
  #par(mfrow = c(4,5))
  for(j in 1:d){
    plot(GDFMM$gamma[j,], type = 'l', main = paste0(expression(gamma), "_",j))
  }
  
  # 
  # par(mfrow = c(1,d), mar = c(2,2,1,1))
  # for(j in 1:d){
  #   acf(GDFMM$gamma[j,], main = paste0("ACF - ",expression(gamma), "_",j))
  # }
}



# U
# par(mfrow = c(1,d))
for(j in 1:d){
  plot(GDFMM$U[j,], type = 'l', main = paste0("U_",j))
}

# K
par(mfrow = c(1,1), bty = "l")
plot(GDFMM$K, type = 'l', main = "K")

par(mfrow = c(1,1), bty = "l")
barplot(table(GDFMM$K), main = "Hist - K")

# sigma (solo per il caso con prior Normal)
if(prior == "Normal"){
  sigma = unlist(lapply(GDFMM$sigma, FUN = function(sigma_it){sigma_it[1]}))
  par(mfrow = c(1,2), bty = "l")
  plot(sigma, type = 'l', main = "sigma^2 (variance) - traceplot")
  plot(density(sigma), main = "sigma^2 (variance) - density")  
}


```



## Final plot
```{r}
pk_MCMC = table(GDFMM$K[(niter/2) : niter])/ length((niter/2) : niter)
names(pk_MCMC) = paste0(names(pk_MCMC),".35")
grid_lambda = seq(1e-8,60,length.out = 10000)

B = 10000
lambda_prior = rgamma(n=B, shape = a_lambda, rate = b_lambda)
M_mar_prior = rpois(n=B, lambda = lambda_prior)



par(mar = c(2,2,2,1), bty = "l")
plot(grid_lambda, dgamma(grid_lambda, shape = a_lambda, rate = b_lambda), ylim = c(0,0.25),
     lwd = 2, lty = 1, type = "l", main = "Prior comparison", ylab = " ", col = "blue")
points(pk_MCMC, type = "h", col = "black", xlab = "K")
points(table(M_mar_prior)/B, type = "h", col = "red", xlab = "M")
legend("topright", c("K - MC","Lambda","M - MC"), col = c("black","blue","red"), pch = 16)

```


## Hyperparameters (gamma basso)

$P_0$ non la cambio, tanto non ha effetto a prior.

$(\Lambda,\gamma_1,\dots,\gamma_d)$ prior elicitation

```{r}
Exp_Lambda   =  20
Var_Lambda   =  3
gamma_guess  =  1/400 
Lambda_guess = Exp_Lambda

b_lambda = Exp_Lambda/Var_Lambda
a_lambda = Exp_Lambda * b_lambda

a_gamma = a_lambda/d
b_gamma = a_gamma / (gamma_guess * Lambda_guess) 

# plot
lambda_prior = rgamma(n=10000, shape = a_lambda, rate = b_lambda)
gamma_mar_prior = rgamma(n=10000, shape = a_gamma, rate = lambda_prior*b_gamma)
par(mar = c(2,2,2,1), bty = "l")
plot(density(gamma_mar_prior), lwd = 2, main = "Marginal for gamma", ylab = " ")

# cat("\n quantile for L(gamma) (MC estimate) \n")
# quantile(gamma_mar_prior, probs = c(0.5, 0.95, 0.99))

grid_lambda = seq(1e-8,100,length.out = 10000)
par(mar = c(2,2,2,1), bty = "l")
plot(grid_lambda, dgamma(grid_lambda, shape = a_lambda, rate = b_lambda), 
     lwd = 2, lty = 1, type = "l", main = "prior for lambda", ylab = " ")

```


## Run 

### Setup

```{r}
niter  <-  10000
burnin <-  1
thin   <-    1


# initial values
beta0 = rep(-2,dt$r)
Sigma0 = diag(dt$r)

Lambda0 = Exp_Lambda
gamma0 = rep(1e-4,d)
Mstar0 = 3

cluster_mean = data_med4season %>% group_by(Kmeans) %>% 
                summarise(ClusterMean = mean(Result)) %>% ungroup() %>% pull(ClusterMean)
cluster_var  = data_med4season %>% group_by(Kmeans) %>% 
                summarise(ClusterVar = var(Result)) %>% ungroup() %>% pull(ClusterVar)
initial_partition = unlist(unlist(dt$initialPartition))


option = set_options( "mu0" = mu0,"sigma0"= sigma0, "k0"= k0, "nu0"=nu0, 
                      "Adapt_MH_hyp2" = 0.234, "Adapt_MH_var0"=0.1,
                      "proposal_Mstar" = 1,
                      "Lambda0" = Lambda0, "gamma0" = gamma0, "Mstar0" = Mstar0,
                      "beta0" = beta0, "Sigma0" = Sigma0,
                      "alpha_gamma" = a_gamma, "beta_gamma" = b_gamma, 
                      "alpha_lambda" = a_lambda, "beta_lambda" = b_lambda,
                      "init_mean_cluster" = c(centers, rep(0,Mstar0)), 
                      "init_var_cluster" = c(cluster_var, rep(1,Mstar0)), 
                      "partition" = initial_partition,
                      "IncludeCovariates" = FALSE,
                      "UseData" = F,
                      "UpdateU" = T, "UpdateM" = T, "UpdateGamma" = F, 
                      "UpdateS" = T, "UpdateTau" = T, "UpdateLambda" = T,
                      "UpdateBeta" = F )

prior = "Normal-InvGamma"


```


```{r}
GDFMM = ConditionalSampler(dt[1:11], niter, burnin, thin, seed = 123, option = option, FixPartition = F,
                           P0.prior = prior, algorithm = "Neal2")
```

### Chains
```{r, echo = F}
if(option$UpdateLambda){
  #Lambda
  plot(GDFMM$lambda, type = 'l', main = expression(Lambda))
  hist(GDFMM$lambda, main = expression(Lambda))
}


if(option$UpdateM){
  # Mstar
  par(bty = "l")
  plot(GDFMM$Mstar, type = 'l', main = "Mstar")
  #acf(GDFMM$Mstar)
}


if(option$UpdateGamma){
  # gamma
  #par(mfrow = c(4,5))
  for(j in 1:d){
    plot(GDFMM$gamma[j,], type = 'l', main = paste0(expression(gamma), "_",j))
  }
  
  # 
  # par(mfrow = c(1,d), mar = c(2,2,1,1))
  # for(j in 1:d){
  #   acf(GDFMM$gamma[j,], main = paste0("ACF - ",expression(gamma), "_",j))
  # }
}



# U
# par(mfrow = c(1,d))
for(j in 1:d){
  plot(GDFMM$U[j,], type = 'l', main = paste0("U_",j))
}

# K
par(mfrow = c(1,1), bty = "l")
plot(GDFMM$K, type = 'l', main = "K")

par(mfrow = c(1,1), bty = "l")
barplot(table(GDFMM$K), main = "Hist - K")

# sigma (solo per il caso con prior Normal)
if(prior == "Normal"){
  sigma = unlist(lapply(GDFMM$sigma, FUN = function(sigma_it){sigma_it[1]}))
  par(mfrow = c(1,2), bty = "l")
  plot(sigma, type = 'l', main = "sigma^2 (variance) - traceplot")
  plot(density(sigma), main = "sigma^2 (variance) - density")  
}


```



## Final plot
```{r}
pk_MCMC = table(GDFMM$K[(niter/2) : niter])/ length((niter/2) : niter)
names(pk_MCMC) = paste0(names(pk_MCMC),".35")
pm_MCMC = table(GDFMM$K[(niter/2) : niter] + GDFMM$Mstar[(niter/2) : niter])/ length((niter/2) : niter)
names(pm_MCMC) = paste0(names(pm_MCMC),".15")
grid_lambda = seq(1e-8,60,length.out = 10000)

B = 10000
lambda_prior = rgamma(n=B, shape = a_lambda, rate = b_lambda)
M_mar_prior = rpois(n=B, lambda = lambda_prior)



par(mar = c(2,2,2,1), bty = "l")
plot(grid_lambda, dgamma(grid_lambda, shape = a_lambda, rate = b_lambda), ylim = c(0,0.25),
     lwd = 2, lty = 1, type = "l", main = "Prior comparison", ylab = " ", col = "blue")
points(pk_MCMC, type = "h", col = "black", xlab = "K")
points(pm_MCMC, type = "h", col = "orange", xlab = "K")
points(table(M_mar_prior)/B, type = "h", col = "red", xlab = "M")
legend("topright", c("K - MC","Lambda","M - MC"), col = c("black","blue","red"), pch = 16)

```

